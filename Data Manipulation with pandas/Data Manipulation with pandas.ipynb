{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7f70e8-501f-438e-9a8d-5745fbcf334f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Manipulation with pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "These are my notes for DataCamp's course [_Data Manipulation with pandas_](https://www.datacamp.com/courses/data-manipulation-with-pandas).\n",
    "\n",
    "Presented by Maggie Matsui, Curriculum Manager at DataCamp, and Richie Cotton, Learning Solutions Architect at DataCamp. Collaborators are Amy Peterson, Adel Nehme, Alex Yarosh, and Justin Saddlemeyer.\n",
    "\n",
    "Prerequisite:\n",
    "\n",
    "- [_Intermediate Python_](../Intermediate%20Python/Intermediate%20Python.ipynb)\n",
    "\n",
    "This course is part of these tracks:\n",
    "\n",
    "- Data Analyst with Python\n",
    "- Data Manipulation with Python\n",
    "- Data Scientist with Python\n",
    "- Data Scientist Professional with Python\n",
    "- Python Programmer\n",
    "\n",
    "## Versions\n",
    "\n",
    "The course uses Python '3.9.7 (default, Sep 10 2021, 00:03:59) \\n[GCC 7.5.0]'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad97bf-6585-405e-8ce1-8a931ac6f722",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports\n",
    "\n",
    "Imports are placed here for convenience and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8063b-524d-4ac7-96c2-e7406e79e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3dd2d-697f-48ed-876f-6add78169aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets\n",
    "\n",
    "| Name | File |\n",
    "| :--- | :--- |\n",
    "| Avocado Prices | avoplotto.pkl |\n",
    "| Walmart Sales | sales_subset.csv |\n",
    "| Homelessness Data | homelessness.csv |\n",
    "| Temperatures | temperatures.csv |\n",
    "\n",
    "### Walmart Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a04f5-795b-449c-a5dc-8a7fa5a1bc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sales_subset.csv into a DataFrame.\n",
    "sales = pd.read_csv(\"sales_subset.csv\", index_col=0, parse_dates=[\"date\"])\n",
    "print(sales.head(), \"\\n\")\n",
    "print(sales.info(), \"\\n\")\n",
    "print(sales.shape, \"\\n\")\n",
    "print(sales.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2ae72-f1e4-44f9-8ebc-609137caa2cd",
   "metadata": {},
   "source": [
    "### Homelessness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5aa445-6464-4fc0-957e-dd2687cdd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load homelessness.csv into a DataFrame.\n",
    "homelessness = pd.read_csv(\"homelessness.csv\", index_col=0)\n",
    "print(homelessness.head(), \"\\n\")\n",
    "print(homelessness.info(), \"\\n\")\n",
    "print(homelessness.shape, \"\\n\")\n",
    "print(homelessness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ac81a-31a6-42dd-a8f4-bfe015cc7351",
   "metadata": {},
   "source": [
    "### Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d199fd-0bc8-4392-b39e-b6482f33a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temperatures.csv into a DataFrame.\n",
    "temperatures = \\\n",
    "    pd.read_csv(\n",
    "        \"temperatures.csv\",\n",
    "        index_col=None,\n",
    "        usecols=[1, 2, 3, 4],\n",
    "        parse_dates=[0])\n",
    "print(temperatures.head(), \"\\n\")\n",
    "print(temperatures.info(), \"\\n\")\n",
    "print(temperatures.shape, \"\\n\")\n",
    "print(temperatures.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f45b3-f61a-4783-9b9a-c62e648cddb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transforming DataFrames\n",
    "\n",
    "### Introducting DataFrames\n",
    "\n",
    "Pandas is built on top of NumPy and Matplotlib. Pandas organizes data in rectangular or tabular form. Pandas often provides multiple ways of doing something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8eb37-02bf-423f-91f2-b7ccf9fb5a44",
   "metadata": {},
   "source": [
    "#### Create a DataFrame from a Dictionary (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5be06-f654-44ae-8e0a-c5774739fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the example dogs DataFrame.\n",
    "# Extra: Make sure the values for date_of_birth have dtype datetime64[ns].\n",
    "# Later in the course, the examples use \"Grey\" instead of \"Gray\".\n",
    "date_of_birth = np.array(\n",
    "    [\"2013-07-01\", \"2016-09-16\", \"2014-08-25\", \"2011-12-11\",\n",
    "        \"2017-01-20\", \"2015-04-20\", \"2018-02-27\"],\n",
    "    dtype=\"datetime64[ns]\")\n",
    "print(date_of_birth)\n",
    "print()\n",
    "\n",
    "# Create the DataFrame and explore it.\n",
    "data_dict = {\n",
    "    \"name\" : [\"Bella\", \"Charlie\", \"Lucy\", \"Cooper\", \"Max\", \n",
    "              \"Stella\", \"Bernie\"],\n",
    "    \"breed\" : [\"Labrador\", \"Poodle\", \"Chow Chow\", \"Schnauzer\", \"Labrador\",\n",
    "               \"Chihuahua\", \"St. Bernard\"],\n",
    "    \"color\" : [\"Brown\", \"Black\", \"Brown\", \"Gray\", \"Black\", \"Tan\", \"White\"],\n",
    "    \"height_cm\" : [56, 43, 46, 49, 59, 18, 77],\n",
    "    \"weight_kg\" : [25, 23, 22, 17, 29, 2, 74],\n",
    "    \"date_of_birth\" : date_of_birth}\n",
    "dogs = pd.DataFrame(data_dict)\n",
    "\n",
    "# Explore the content of a new DataFrame.\n",
    "print(dogs.head())\n",
    "print()\n",
    "\n",
    "# Print a summary of information about the DataFrame.\n",
    "print(dogs.info())\n",
    "print()\n",
    "\n",
    "# Print the shape of the DataFrame (rows, columns).\n",
    "print(dogs.shape)\n",
    "print()\n",
    "\n",
    "# Create summary statistics.\n",
    "print(dogs.describe())\n",
    "print()\n",
    "\n",
    "# Get the values from the DataFrame as NumPy array containing the\n",
    "# rows of the DataFrame.\n",
    "print(type(dogs.values))\n",
    "print(dogs.values)\n",
    "print()\n",
    "\n",
    "# Get the names of the columns.\n",
    "print(dogs.columns)\n",
    "print()\n",
    "\n",
    "# Get the names of the rows. Here, we have a RangeIndex object with row\n",
    "# numbers since there aren't any row labels.\n",
    "print(dogs.index)\n",
    "print()\n",
    "\n",
    "# Let Jupyter format the DataFrame nicely.\n",
    "dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425a419-8b32-4709-ad75-51535d6b0233",
   "metadata": {},
   "source": [
    "#### Create a DataFrame from a Tuple of Tuples (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee2058-e847-4607-8172-823455824d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame from a tuple of tuples (as if the data came from a\n",
    "# database query). Note how the dates must be handled.\n",
    "dogs_columns = (\"name\", \"breed\", \"color\", \"height_cm\", \"weight_kg\",\n",
    "                \"date_of_birth\")\n",
    "dogs_data = (\n",
    "    ('Bella', 'Labrador', 'Brown', 56, 25, datetime.datetime.fromisoformat('2013-07-01')),\n",
    "    ('Charlie', 'Poodle', 'Black', 43, 23, datetime.datetime.fromisoformat('2016-09-16')),\n",
    "    ('Lucy', 'Chow Chow', 'Brown', 46, 22, datetime.datetime.fromisoformat('2014-08-25')),\n",
    "    ('Cooper', 'Schnauzer', 'Gray', 49, 17, datetime.datetime.fromisoformat('2011-12-11')),\n",
    "    ('Max', 'Labrador', 'Black', 59, 29, datetime.datetime.fromisoformat('2017-01-20')),\n",
    "    ('Stella', 'Chihuahua', 'Tan', 18, 2, datetime.datetime.fromisoformat('2015-04-20')),\n",
    "    ('Bernie', 'St. Bernard', 'White', 77, 74, datetime.datetime.fromisoformat('2018-02-27'))\n",
    ")\n",
    "dogs2 = pd.DataFrame(data=dogs_data, columns=dogs_columns)\n",
    "dogs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fc33a-f586-4deb-ba2d-a41ffca9ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check equivalence of the dogs and dogs2 DataFrames.\n",
    "print(dogs.equals(dogs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684963b-a1bc-4f25-a48a-e3ae29a158f7",
   "metadata": {},
   "source": [
    "#### Load Homeless Data and Print Information (Exercise)\n",
    "\n",
    "Homelessness is a DataFrame containing estimates of homelessness in each U.S. state in 2018.\n",
    "- The individual column is the number of homeless individuals not part of a family with children.\n",
    "- The family_members column is the number of homeless individuals part of a family with children.\n",
    "- The state_pop column is the state's total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282d574-72f3-42fa-94d7-4a61aaab0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parts of a DataFrame are the values, index, and columns.\n",
    "# Print each of the three parts.\n",
    "print(homelessness.values)\n",
    "print()\n",
    "print(homelessness.columns)\n",
    "print()\n",
    "print(homelessness.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4edd0-8660-4695-b016-c46c5d4b4fda",
   "metadata": {},
   "source": [
    "### Sorting and Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b31ed-cb92-4185-ae55-ec9ce9bb7511",
   "metadata": {},
   "source": [
    "#### Sort Rows by Values in a Column (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec650f83-a152-44de-85fe-67731ee77fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows by values in a column.\n",
    "dogs.sort_values(\"weight_kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34543638-8c05-463b-88cf-1ed99af81b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort descending (ascending=False).\n",
    "dogs.sort_values(\"weight_kg\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834dcfc-dc23-4c28-adda-1338cf04858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows by multiple columns.\n",
    "dogs.sort_values([\"weight_kg\", \"height_cm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad4605-8e4c-4ffb-b7de-b4cd24f0bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows by multiple columns, ascending for one column and descending\n",
    "# for another. This sorts by weight_kg in ascending order, then by\n",
    "# height_cm in descending order.\n",
    "dogs.sort_values([\"weight_kg\", \"height_cm\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f0509-2a00-4b79-bbce-eff009adb9d2",
   "metadata": {},
   "source": [
    "#### Create Subsets from One or More Columns of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b09cea-ef33-44ef-a042-51d03f10e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series subset from a column of a DataFrame.\n",
    "subset1 = dogs[\"name\"]\n",
    "print(\"type(subset1):\", type(subset1))\n",
    "subset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6484c6-6c50-4721-8daf-1da8c93906a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame subset from a column of a DataFrame.\n",
    "subset2 = dogs[[\"name\"]]\n",
    "print(\"type(subset2):\", type(subset2))\n",
    "subset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552005e-bb73-4210-ab1d-3751d03ad49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame subset containing multiple columns.\n",
    "# Subsetting by multiple columns requires [[ ... ]]. The inner\n",
    "# [ ... ] is the list of column names. The outer [ ... ] performs the\n",
    "# subsetting.\n",
    "dogs[[\"breed\", \"height_cm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de69ff5-14c0-42df-b65d-04af7bdce805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using multiple columns, a second way that emphasizes\n",
    "# how the [[ ... ]] work.\n",
    "cols_to_subset = [\"breed\", \"height_cm\"]\n",
    "dogs[cols_to_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23a3f7-a6b3-4590-810e-2b9c2a477e58",
   "metadata": {},
   "source": [
    "#### Subset Using a Boolean Filter Mask (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c89b85-3e06-4ee0-9589-30fe33b3693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean filter mask.\n",
    "dogs[\"height_cm\"] > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc25068-8f98-4025-8b12-e2e203d5688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and apply the boolean filter mask.\n",
    "dogs[dogs[\"height_cm\"] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ea2aa-1fb9-4bbd-83e7-72cb26de5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using a boolean filter mask based on text data.\n",
    "dogs[dogs[\"breed\"] == \"Labrador\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdd82f-8f20-40e5-8b9d-2b7fdcd847c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset based on a date. I suspect this is using string comparison\n",
    "# rather than comparing datetime objects.\n",
    "dogs[dogs[\"date_of_birth\"] < \"2015-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1803f3-8f97-4825-bf29-f590debaaa5b",
   "metadata": {},
   "source": [
    "#### Subset Based on Multiple Conditions (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396ea64-f395-432e-b787-48eec8204411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset based on multiple conditions.\n",
    "is_lab = dogs[\"breed\"] == \"Labrador\"\n",
    "is_brown = dogs[\"color\"] == \"Brown\"\n",
    "print(is_lab & is_brown)\n",
    "dogs[is_lab & is_brown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc2ab9-42f3-4352-878c-5c8918ae9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset based on multiple conditions, using one line of code.\n",
    "dogs[(dogs[\"breed\"] == \"Labrador\") & (dogs[\"color\"] == \"Brown\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8dfcc-2988-4396-a5fc-9cd598bc640b",
   "metadata": {},
   "source": [
    "#### Subset Based on Multiple Categories Using `.isin()` (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c9ef6-11c9-48b2-95ff-832d9fa27df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset based on multiple categories using .isin().\n",
    "is_black_or_brown = dogs[\"color\"].isin([\"Black\", \"Brown\"])\n",
    "dogs[is_black_or_brown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5df7c-6ae0-46bf-bd68-4517e5eb8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra credit.\n",
    "# Using | to produce the equivalent of .isin().\n",
    "is_black_or_brown = (dogs[\"color\"] == \"Black\") | (dogs[\"color\"] == \"Brown\")\n",
    "dogs[is_black_or_brown]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782e20a-dd7d-4300-84fc-e687c89fcb76",
   "metadata": {},
   "source": [
    "#### Sort a DataFrame by a Column and Show the First Few Rows (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932a2ef-4321-4a29-9fa0-8f718c7329a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort homelessness by the \"individuals\" column and show the first few rows.\n",
    "homelessness_ind = homelessness.sort_values(\"individuals\")\n",
    "homelessness_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2152cad-7ca7-4cf4-ae3e-a1a1de01e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort homelessness by the \"family_members\" column descending and show the\n",
    "# first few rows.\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\", ascending=False)\n",
    "homelessness_fam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440bdfb-c149-4a3b-87dc-cb664d244136",
   "metadata": {},
   "source": [
    "#### Sort a DataFrame by Two Columns, One Ascending, One Descending (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98081467-b1b7-4ece-8a72-bd286ac5cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort homelessness by \"region\" ascending and then by \"family_members\"\n",
    "# descending.\n",
    "homelessness_reg_fam = homelessness.sort_values([\"region\", \"family_members\"], ascending=[True, False])\n",
    "homelessness_reg_fam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a96b9-44f6-484c-b1a8-b78a062f20ce",
   "metadata": {},
   "source": [
    "#### Create a DataFrame Subset from One Column (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e13f9a-3fd5-4ce4-853b-426cc6b74495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the \"individuals\" column from homelessness.\n",
    "# The course says the result is a DataFrame, but it is a Series.\n",
    "individuals = homelessness[\"individuals\"]\n",
    "print(type(individuals))\n",
    "individuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfdeb5-ea0f-4ac6-bfb7-3c272a44ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing the \"individuals\" column from homelessness.\n",
    "individuals2 = homelessness[[\"individuals\"]]\n",
    "print(type(individuals2))\n",
    "individuals2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644bb51a-679b-445c-96a9-00d31033886b",
   "metadata": {},
   "source": [
    "#### Create a DataFrame from a Subset of Multiple Columns (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049755e-a3ad-456a-a965-3a23fe664c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the \"state\" and \"family_members\" columns of\n",
    "# homelessness.\n",
    "state_fam = homelessness[[\"state\", \"family_members\"]]\n",
    "state_fam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7606c2-ac8e-4e84-bc3d-c1a4d9cbe76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the \"individuals\" and \"state\" columns of\n",
    "# homelessness.\n",
    "ind_state = homelessness[[\"individuals\", \"state\"]]\n",
    "ind_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2a765-cf9f-496b-9dc7-7329ffec8121",
   "metadata": {},
   "source": [
    "#### Create a DataFrame Subset Using a Boolean Filter (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e05c7-005a-440d-9f4c-0b83acf2abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows where individuals > 10000.\n",
    "ind_gt_10k = homelessness[homelessness[\"individuals\"] > 10000]\n",
    "ind_gt_10k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d762ca-1161-404e-a539-a6735f137a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows where region is \"Mountain\".\n",
    "mountain_reg = homelessness[homelessness[\"region\"] == \"Mountain\"]\n",
    "mountain_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451a2d7-f33a-41b6-9f6e-7e05c18ba1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows where family_members < 1000 and region == \"Pacific\".\n",
    "fam_lt_1k_pac = homelessness[(homelessness[\"family_members\"] < 1000) \\\n",
    "                & (homelessness[\"region\"] == \"Pacific\")]\n",
    "fam_lt_1k_pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6b300-060b-48e1-9b46-09a76b6c1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows in homelessness where the region is in \"South Atlantic\" or\n",
    "# \"Mid-Atlantic\".\n",
    "south_mid_atlantic = homelessness[homelessness[\"region\"].isin(\n",
    "    [\"South Atlantic\", \"Mid-Atlantic\"])]\n",
    "south_mid_atlantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95500f-7319-478a-b1f9-0cc0bc93a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows where the state is in the Mojave Desert states.\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "mojave_homelessness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497d934-6d53-4425-8dd7-fdea9f540321",
   "metadata": {},
   "source": [
    "### New Columns\n",
    "\n",
    "#### Create New Columns from Existing Columns (Demonstration)\n",
    "\n",
    "It is often necessary to create new columns in a DataFrame that are derived from existing columns to simplify further analysis. This process is called \"mutating a DataFrame\", \"transforming a DataFrame\", or \"feature engineering\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54bc43-3850-4e53-9537-8b73add80932",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs[\"height_m\"] = dogs[\"height_cm\"] / 100\n",
    "\n",
    "# Now calculate the BMI for the dogs: kg / m ** 2.\n",
    "# The numbers that come out show what a terrible measurement BMI is.\n",
    "# The values should be similar for humans and dogs.\n",
    "dogs[\"bmi\"] = dogs[\"weight_kg\"] / dogs[\"height_m\"] ** 2\n",
    "dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22ef79-4336-46c8-9464-597275231674",
   "metadata": {},
   "source": [
    "#### Perform Multiple Manipulations of a DataFrame (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4a160-d559-4ec8-bdbe-61bf34ddef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple manipulations by finding the names of skinny tall dogs.\n",
    "# Find the rows for skinny dogs.\n",
    "bmi_lt_100 = dogs[dogs[\"bmi\"] < 100]\n",
    "\n",
    "# Sort the rows by height descending to get the tallest dogs at the top.\n",
    "bmi_lt_100_height = bmi_lt_100.sort_values(\"height_cm\", ascending=False)\n",
    "\n",
    "# Keep only the columns we're interested in.\n",
    "bmi_lt_100_height[[\"name\", \"height_cm\", \"bmi\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0c0fd-c558-4f57-8d03-eaa0d5e3cf7e",
   "metadata": {},
   "source": [
    "#### Add Columns to a DataFrame (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e071b0-9b4f-427d-acbe-663a954fbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"total\" and \"individuals_p\" columns to homelessness.\n",
    "homelessness[\"total\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"]\n",
    "homelessness[\"p_individuals\"] = homelessness[\"individuals\"] / homelessness[\"total\"]\n",
    "homelessness.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fe226-cbe9-4ad9-a5f2-fe819e237c3a",
   "metadata": {},
   "source": [
    "#### Analyze and Return Data from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c2303-17df-4cb9-a864-5f3c0a70410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which state has the highest number of homeless individuals per 10000 in\n",
    "# the state?\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"]\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "state = result.iloc[0]\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4c6a4-3f93-4825-899d-ceef713c8f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ff282-600a-4e89-ace6-b24f36df130c",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Summary statistics can be calculated on individual columns of a DataFrame.\n",
    "\n",
    "```Python\n",
    "# Summary statistics for all columns.\n",
    "dogs.describe()\n",
    "# The mean of one numerical column.\n",
    "dogs[\"height_cm\"].mean()\n",
    "```\n",
    "\n",
    "Other summary statistics include `.median()`, `.mode()`, `.max()`, `.min()`, `.var()`, `.std()`, `.sum()`, `.quantile()`. Summary statistics work for date columns.\n",
    "\n",
    "There is a method, `.agg()`, for custom summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cd9ba-700e-492a-bd45-6403f72f58e5",
   "metadata": {},
   "source": [
    "#### Using the `.agg()` Method for Custom Summary Statistics (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc69e36-16b7-4d77-ba63-8568de1df290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple example of using the .agg() method.\n",
    "# Single column result\n",
    "print(dogs[\"weight_kg\"])\n",
    "def pct30(column):\n",
    "    return column.quantile(0.3)\n",
    "\n",
    "dogs[\"weight_kg\"].agg(pct30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f663afc-2a61-4cc2-94bd-74cb8d9414c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-column result.\n",
    "dogs[[\"weight_kg\", \"height_cm\"]].agg(pct30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c5204-20e4-43b9-bd65-18a42db36fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .agg() to compute multiple summary statistics.\n",
    "def pct40(column):\n",
    "    return column.quantile(0.4)\n",
    "\n",
    "dogs[[\"weight_kg\", \"height_cm\"]].agg([pct30, pct40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08741406-f2d8-4b4d-bb81-aed4984ed9e5",
   "metadata": {},
   "source": [
    "#### Calculate Cumulative Statistics (Demonstration)\n",
    "\n",
    "`.cumsum()`, `.cummax()`, `.cummin()`, and `.cumprod()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088af5-afe4-4d35-b1d3-072baeaf882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative sum.\n",
    "dogs[\"weight_kg\"].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc426989-dc1f-465c-82a2-af2374a973a1",
   "metadata": {},
   "source": [
    "#### Mean and Median (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6996f17-a104-4928-89ad-f27b1a289b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the sales DataFrame.\n",
    "print(sales.head())\n",
    "print(sales.info())\n",
    "# Print the mean and median of weekly_sales.\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674d316-0bcd-40fa-a453-0df065721423",
   "metadata": {},
   "source": [
    "#### Summarizing Dates (Exercise)\n",
    "\n",
    "Note that the sales[\"date\"] column has dtype `datetime64[ns]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acff97-e0e4-4caa-a74a-36de783082f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum and maximum of the date column.\n",
    "print(sales[\"date\"].max())\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920dc4b-bf8d-4c1e-8974-3c51f6f7a1c7",
   "metadata": {},
   "source": [
    "#### Efficient Summary Statistics Using `.agg()` (Exercise)\n",
    "\n",
    "> The `.agg()` method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c084eae-3806-4269-abda-10b60e0c9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Apply a Function to Calculate Inter-Quartile Range\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(\"75th percentile:\", sales[\"temperature_c\"].quantile(0.75))\n",
    "print(\"25th percentile:\", sales[\"temperature_c\"].quantile(0.25))\n",
    "print(\"inter-quartile range:\", sales[\"temperature_c\"].agg(iqr))\n",
    "print(\"inter-quartile range:\")\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))\n",
    "print(\"inter-quartile range, median:\")\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, \"median\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825edae0-5f69-4a01-a420-c1135b97358b",
   "metadata": {},
   "source": [
    "#### Cumulative Statistics (Exercise)\n",
    "\n",
    "Cumulative statistics calculations return a column of values, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053dd16-9a34-4435-9edc-6d3d58f05cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some cumulative statistics for Store 1 Department 1.\n",
    "# First, create a DataFrame with data for store 1 department 1.\n",
    "# Use parentheses when using the & operator.\n",
    "# Sort by date.\n",
    "sales_1_1 = sales[(sales[\"store\"] == 1) & (sales[\"department\"] == 1)]\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Add new columns for cumulative weekly sales.\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ca617-e08b-417a-8da1-e1d8cabee246",
   "metadata": {},
   "source": [
    "### Counting\n",
    "\n",
    "Categorical data can be counted. The video's example involves counting the number of different dogs that have visited a veterinarian. The data set contains the names and breeds of the dogs who have visited. We need to remove duplicates before counting, using\n",
    "```Python\n",
    "unique_dogs = vet_visits.drop_duplicates(subset=\"name\")\n",
    "```\n",
    "\n",
    "In the example, two dogs of different breeds have the name \"Max\". Drop duplicates using\n",
    "```Python\n",
    "unique_dogs = vet_visits.drop_duplicates(subset=[\"name\", \"breed\"])\n",
    "```\n",
    "\n",
    "Count the dogs by breed using\n",
    "```Python\n",
    "unique_dogs[\"breed\"].value_counts()\n",
    "```\n",
    "The values can be sorted like this:\n",
    "```Python\n",
    "unique_dogs[\"breed\"].value_counts(sort=True)\n",
    "```\n",
    "The values can be normalized like this:\n",
    "```Python\n",
    "unique_dogs[\"breed\"].value_counts(normalize=True)\n",
    "```\n",
    "\n",
    "#### Dropping Duplicates (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd7400-b023-4f3d-a3ef-2ced909cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The course's way of doing this produces DataFrame objects.\n",
    "# My way of doing this produces Series objects.\n",
    "# I preferred to subset first to get rid of the columns we're not interested\n",
    "# in before dropping the duplicates.\n",
    "# Drop duplicate store/type combinations.\n",
    "# store_types = sales[[\"store\", \"type\"]].drop_duplicates()\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(\"store_types.head():\")\n",
    "print(store_types.head())\n",
    "print()\n",
    "\n",
    "# Drop duplicate store/department combinations.\n",
    "# store_depts = sales[[\"store\", \"department\"]].drop_duplicates()\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(\"store_depts.head():\")\n",
    "print(store_depts.head())\n",
    "print()\n",
    "\n",
    "# Subset the rows where is_holiday is True, drop duplicate dates, and\n",
    "# print the \"date\" column.\n",
    "# My approach, where holiday_dates1 is a Series:\n",
    "holiday_dates1 = sales[sales[\"is_holiday\"] == True][\"date\"].drop_duplicates()\n",
    "print(\"holiday_dates1:\", holiday_dates1)\n",
    "print()\n",
    "\n",
    "# The course's solution to the exercise, where holiday_dates2 is a DataFrame.\n",
    "holiday_dates2 = sales[sales[\"is_holiday\"] == True].drop_duplicates(subset=[\"date\"])\n",
    "print(\"holiday_dates2:\", holiday_dates2[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54cc6b-42f7-41ca-b59b-c28d428216f2",
   "metadata": {},
   "source": [
    "#### Counting Categorial Variables (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29652f-9880-42ff-b834-b021ddf23755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores of each type.\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type.\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort.\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort.\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929521e-f767-4f04-a0d4-cfe805956f99",
   "metadata": {},
   "source": [
    "#### Sort and Count (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a917ada-9031-4d14-805c-efba11ee7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I experimented with sorting and counting.\n",
    "# I wanted to know the counts for the store and type combinations,\n",
    "# sorted by store and then by type.\n",
    "# .value_counts() should be named .count_values().\n",
    "store_types = sales[[\"store\", \"type\"]].sort_values([\"store\", \"type\"])\n",
    "print(store_types.info())\n",
    "# This returns a pandas.Series with a MultiIndex.\n",
    "# Watch out! sort=True by default.\n",
    "store_types_value_counts = store_types.value_counts(sort=False)\n",
    "print(type(store_types_value_counts))\n",
    "print(store_types_value_counts)\n",
    "print(store_types_value_counts.index)\n",
    "\n",
    "# Alternatively,specify the subset as part of the call to .value_counts().\n",
    "store_types_value_counts2 = \\\n",
    "    sales.sort_values([\"store\", \"type\"]).\\\n",
    "        value_counts(subset=[\"store\", \"type\"], sort=False)\n",
    "print(store_types_value_counts.equals(store_types_value_counts2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c2330-c096-4d72-8024-675087b34207",
   "metadata": {},
   "source": [
    "### Grouped Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f0809-22a3-4b5e-8052-d82245224b9c",
   "metadata": {},
   "source": [
    "#### Summaries by Group (Demonstration)\n",
    "\n",
    "Use the `.groupby()` method to make this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ec725-d66f-4cfa-9546-3ea965ded3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summaries by group, doing it the hard way.\n",
    "print(dogs[dogs[\"color\"] == \"Black\"][\"weight_kg\"].mean())\n",
    "print(dogs[dogs[\"color\"] == \"Brown\"][\"weight_kg\"].mean())\n",
    "print(dogs[dogs[\"color\"] == \"Gray\"][\"weight_kg\"].mean())\n",
    "print(dogs[dogs[\"color\"] == \"Tan\"][\"weight_kg\"].mean())\n",
    "print(dogs[dogs[\"color\"] == \"White\"][\"weight_kg\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a77222-b6fb-476a-b796-f1d4a4ebc2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .groupby(), which creates a DataFrameGroupBy object.\n",
    "print(dogs.groupby(\"color\"))\n",
    "print(dogs.groupby(\"color\")[\"weight_kg\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770535e-a4dd-41c7-bee2-996eff09affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .agg() to get multiple grouped statistics.\n",
    "print(dogs.groupby(\"color\")[\"weight_kg\"].agg([\"min\", \"max\", \"sum\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8ee3-ca18-45c8-8999-8f18a8237372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b171d6-5461-4460-b762-0bbd81754847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and aggregate by multiple columns.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].mean())\n",
    "print()\n",
    "\n",
    "# When using .agg(), pass \"mean\". The result is the same.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].agg(\"mean\"))\n",
    "print()\n",
    "\n",
    "# Calculate statistics.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].agg(\n",
    "    [\"mean\", \"min\", \"max\", \"sum\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e34d3-5e8c-4ce2-b443-27f2adc17ca3",
   "metadata": {},
   "source": [
    "#### Grouped Summary Statistics Without Using `.groupby()` (Exercise)\n",
    "\n",
    "From the course:\n",
    "\n",
    "> While .groupby() is useful, you can calculate grouped summary statistics without it.\n",
    "\n",
    "> Walmart distinguishes three types of stores: \"supercenters,\" \"discount stores,\" and \"neighborhood markets,\" encoded in this dataset as type \"A,\" \"B,\" and \"C.\" In this exercise, you'll calculate the total sales made at each store type, without using .groupby(). You can then use these numbers to see what proportion of Walmart's total sales were made at each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a516907-54ed-42aa-8ba9-84402a60f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sales by type of store.\n",
    "# The type of sales_all, sales_A, sales_B, sales_C is numpy.float64.\n",
    "# This enables the division of the items of a list by a scalar.\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "print(type(sales_all))\n",
    "# For the vectorized division to work, all values must be NumPy objects,\n",
    "# here, numpy.float64 objects.\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a55cc0-efdf-4bd3-85af-821b5733bba8",
   "metadata": {},
   "source": [
    "#### Grouped Summary Statistics Using `.groupby()` (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de79903-cc7f-4a36-9520-e18e99a57983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the same calculations using .groupby().\n",
    "# This was my approach:\n",
    "print(sales.groupby(\"type\")[\"weekly_sales\"].sum() / sales[\"weekly_sales\"].sum())\n",
    "print()\n",
    "# This was the course's approach:\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "print(sales_by_type / sum(sales_by_type))\n",
    "print()\n",
    "\n",
    "# Extra: Three different ways to calculate the sum of sales_by_type:\n",
    "print(sales_by_type.sum())\n",
    "print(sum(sales_by_type))\n",
    "print(np.sum(sales_by_type))\n",
    "print()\n",
    "\n",
    "# Group by \"type\" and \"is_holiday\" and calculate sales proportions.\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)\n",
    "print(sales_by_type_is_holiday / sales_by_type_is_holiday.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf1fcf-031a-4d86-a32c-b7645b2d59b1",
   "metadata": {},
   "source": [
    "#### Multiple Grouped Summaries (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacedb98-c0db-467a-8317-ac8ca01084dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"]\\\n",
    "    .agg([\"min\", \"max\", \"mean\", \"median\"])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l:\n",
    "# get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")\\\n",
    "    [[\"unemployment\", \"fuel_price_usd_per_l\"]]\\\n",
    "    .agg([\"min\", \"max\", \"mean\", \"median\"])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eae7b3-da35-4e2b-b12c-5d70f8300899",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "\n",
    "Use the `.pivot_table()` method to create the equivalent of a spreadsheet pivot table. Use the `index` parameter to specify the column(s) you want to group by. Use the `values` parameter to specify the column you want to summarize. See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b970a-a353-48c7-86ee-7ad21866215b",
   "metadata": {},
   "source": [
    "#### Simple Pivot Table (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa7827-c5f8-4e5e-bfe2-7fe86838bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .groupby() and .pivot_table() to achieve the same result.\n",
    "# For a pivot table, the default for aggfunc is \"mean\".\n",
    "# This data set is too small.\n",
    "# The output from pivot_table shows the values column and the summary\n",
    "# statistic method.\n",
    "# One pivot, one values column, one summary statistic.\n",
    "# Pass a list to aggfunc to get its name included in the output table.\n",
    "print(dogs.groupby(\"color\")[\"weight_kg\"].mean())\n",
    "print()\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", aggfunc=\"mean\"))\n",
    "print()\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", aggfunc=[\"mean\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162f7da-d156-43c6-999a-5e696c75aecb",
   "metadata": {},
   "source": [
    "#### Pivot Table with Multiple Summary Statistics (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9acef1b-2a65-48b7-b41d-334da51890da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple summary statistics.\n",
    "print(dogs.groupby(\"color\")[\"weight_kg\"].agg([\"mean\", \"median\"]))\n",
    "print()\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", aggfunc=[\"mean\", \"median\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3e285-ae61-4261-adb1-db8812223b8b",
   "metadata": {},
   "source": [
    "#### Pivot on Multiple Columns (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553de1aa-929a-49dd-9910-5fb2f7156d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot on multiple columns.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean())\n",
    "print()\n",
    "print(dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].agg([\"mean\"]))\n",
    "print()\n",
    "print(dogs.pivot_table(index=[\"color\", \"breed\"], values=\"weight_kg\", aggfunc=\"mean\"))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fb084-9e5c-4094-a70f-704617303f33",
   "metadata": {},
   "source": [
    "#### Pivot on Multiple Columns with Multiple Statistics (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7ffca-c8a4-4575-a9f8-dd793530ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot on multiple columns with multiple summary statistics.\n",
    "print(dogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].agg([\"mean\", \"median\"]))\n",
    "print()\n",
    "print(dogs.pivot_table(index=[\"color\", \"breed\"], values=\"weight_kg\", aggfunc=[\"mean\", \"median\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037f9a8-c1f1-4a19-8a46-7dd60008476e",
   "metadata": {},
   "source": [
    "#### Pivot Table Specifying Columns (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb9ee3-568f-401e-bb8f-42fde0c0a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table to put breeds into the columns.\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", columns=\"breed\", aggfunc=[\"mean\"]))\n",
    "print()\n",
    "# Multiple summary statistics.\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", columns=\"breed\", aggfunc=[\"mean\", \"median\"]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6d34b-242a-4f91-a1db-8ad5e1403b52",
   "metadata": {},
   "source": [
    "#### Fill Missing Values in a Pivot Table (Demonstration)\n",
    "\n",
    "Replace `NaN` with `0` in a pivot table. Personally, I prefer seeing the `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f35c0-dd94-4cb4-ba7a-ee6f1655fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0 in the pivot table.\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", columns=\"breed\", aggfunc=[\"mean\"], fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6fb86-1021-4776-98e6-847e46c5faed",
   "metadata": {},
   "source": [
    "#### Summary Statistics for Rows and Columns (Demonstration)\n",
    "\n",
    "Use the `margins=True` argument to get summary statistics for rows and columns in the table margins.\n",
    "\n",
    "> The `margins` parameter is a shortcut for when you pivoted by two variables, but also wanted to pivot by each of those variables separately: it gives the row and column totals of the pivot table contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eed693-9c37-48fc-8893-dbeb562299d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for rows and column.\n",
    "print(dogs.pivot_table(index=\"color\", values=\"weight_kg\", \n",
    "    columns=\"breed\", aggfunc=[\"mean\"], fill_value=0, margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe0d3b-53a4-4af6-ac33-fa59ae7ef9d4",
   "metadata": {},
   "source": [
    "#### Pivot on One Variable (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2cd06-dc8a-4a03-9967-f7051f541cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean weekly sales for store type using a pivot table.\n",
    "mean_sales_by_type = sales.pivot_table(\n",
    "    index=\"type\", values=\"weekly_sales\", aggfunc=\"mean\")\n",
    "print(mean_sales_by_type)\n",
    "print()\n",
    "\n",
    "# Get the mean and median weekly sales for store type.\n",
    "mean_med_sales_by_type = sales.pivot_table(\n",
    "    index=\"type\", values=\"weekly_sales\", aggfunc=[\"mean\", \"median\"])\n",
    "print(mean_med_sales_by_type)\n",
    "print()\n",
    "\n",
    "# Get the mean weekly sales for store type and holiday.\n",
    "mean_sales_by_type_holiday = sales.pivot_table(\n",
    "    index=[\"type\", \"is_holiday\"], values=\"weekly_sales\", aggfunc=[\"mean\"])\n",
    "print(mean_sales_by_type_holiday)\n",
    "print()\n",
    "# Pivot the above table to put is_holiday in columns.\n",
    "mean_sales_by_type_holiday2 = sales.pivot_table(\n",
    "    index=\"type\", columns=\"is_holiday\", values=\"weekly_sales\", aggfunc=[\"mean\"])\n",
    "print(mean_sales_by_type_holiday2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b7775-11c6-4219-bc7c-efea9ca285b4",
   "metadata": {},
   "source": [
    "#### Fill in Missing Values and Get Row and Column Summary Statistics (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028cf00-6423-49ed-a3fe-ff01e8dfbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean weekly_sales by department and type, replacing missing values\n",
    "# with 0.\n",
    "print(sales.pivot_table(\n",
    "    index=\"department\", columns=\"type\", values=\"weekly_sales\", fill_value=0,\n",
    "    aggfunc=\"mean\"))\n",
    "print()\n",
    "# Print the mean weekly sales by department and type, replacing missing values\n",
    "# with 0, and providing summary means for rows and columns.\n",
    "print(sales.pivot_table(\n",
    "    index=\"department\", columns=\"type\", values=\"weekly_sales\", fill_value=0, \n",
    "    aggfunc=\"mean\", margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf096a-a612-45ca-8d6f-02b9fd562ac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Slicing and Indexing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340a29a-0dcf-40aa-b6e3-f39fb67c8475",
   "metadata": {},
   "source": [
    "### Explicit Indexes\n",
    "\n",
    "#### Setting a Column as an Index (Demonstration)\n",
    "\n",
    "Use the `set_index` method to set the index from a column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966b4a1-4d0d-4421-a8e5-a7c33a7d85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to the names column.\n",
    "# In the example, the color for Cooper has changed from \"Gray\" to \"Grey\".\n",
    "print(dogs)\n",
    "print()\n",
    "dogs_ind = dogs.set_index(\"name\")\n",
    "print(dogs_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3ed79-7ff1-4924-a18e-8bbae0e626b4",
   "metadata": {},
   "source": [
    "#### Remove an Index (Demonstration)\n",
    "\n",
    "Remove an index (restoring the values to a column) using the `reset_index` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac2f6d-2665-4eca-9b94-1b99324d5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index.\n",
    "dogs_ind.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c50341-2000-4626-af39-f149fa35fab9",
   "metadata": {},
   "source": [
    "#### Drop an Index (Demonstration)\n",
    "\n",
    "Drop an index using the `reset_index` method with the argument `drop=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289606c-de48-47f4-a3ee-c5801f9e26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop an index.\n",
    "dogs_ind.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed6599-41ec-4192-88c7-ab0658f52bfc",
   "metadata": {},
   "source": [
    "#### Indexes Make Subsetting Code Cleaner (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf52b63-2368-41e6-ad72-11038fb49bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using the names column.\n",
    "print(dogs[dogs[\"name\"].isin([\"Bella\", \"Stella\"])])\n",
    "# Subset using the index, which contains the names of the dogs.\n",
    "print(dogs_ind.loc[[\"Bella\", \"Stella\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e91d9-ae27-4ee7-b043-2c705f3c6e1b",
   "metadata": {},
   "source": [
    "#### Index Values Don't Need to Be Unique (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfff9f-16ee-464f-89ef-05ea3b32b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Index from the breed Column.\n",
    "# There are two rows with the index \"Labrador\".\n",
    "dogs_ind2 = dogs.set_index(\"breed\")\n",
    "print(dogs_ind2)\n",
    "print()\n",
    "print(dogs_ind2.loc[\"Labrador\"])\n",
    "print()\n",
    "print(dogs_ind2.loc[[\"Labrador\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a930d-e19a-46da-a414-772a3fd0c099",
   "metadata": {},
   "source": [
    "#### Set Multi-level (Hierarchical) Indexes (Demonstration)\n",
    "\n",
    "The idea is that the inner level is nested in the outer level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25484175-1091-4dbb-b267-81473c4dbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hierarchical index using two columns.\n",
    "dogs_ind3 = dogs.set_index([\"breed\", \"color\"])\n",
    "print(dogs_ind3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267bbc2-eb68-445c-af9f-4a3cefcb434c",
   "metadata": {},
   "source": [
    "#### Subset the Outer Level with a List (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07c777-e642-4b5a-8b8f-5862c931d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset using the outer level of a hierarchical index.\n",
    "print(dogs_ind3.loc[[\"Labrador\", \"Chihuahua\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba63afe-cc84-459c-861e-12f7c2d7389d",
   "metadata": {},
   "source": [
    "#### Subset Inner Levels with a List of Tuples (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d00990-830a-4179-8751-f6d22535cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset a dataframe using the inner level of a hierarchical index.\n",
    "print(dogs_ind3.loc[[(\"Labrador\", \"Brown\"), (\"Chihuahua\", \"Tan\")]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317a2d9-4c85-425d-952b-03e91f15aafe",
   "metadata": {},
   "source": [
    "#### Sorting by Index Values (Demonstration)\n",
    "\n",
    "Rows of a DataFrame can be sorted by values using the `.sort_values()` method. Rows of a DataFrame can also be sorted by index values using the `.sort_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac52cff-e0cb-45de-916c-efa94bfb7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by index values.\n",
    "print(dogs_ind3.sort_index())\n",
    "print()\n",
    "# Sort by \"color\" ascending first, then by \"breed\" descending.\n",
    "print(dogs_ind3.sort_index(level=[\"color\", \"breed\"], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d8f29-ebdb-4c12-8c16-d1ed585f481b",
   "metadata": {},
   "source": [
    "#### Problems with Indexes\n",
    "\n",
    "Using indexes causes two problems:\n",
    "- Indexes are just data, and storing data in multiple forms makes it harder to think about\n",
    "- Using indexes violates these tidy data principles (https://vita.had.co.nz/papers/tidy-data.pdf):\n",
    "    - Data is stored in tabular form such as a DataFrame\n",
    "    - Each row of the DataFrame contains a single observation, where each variable is stored in its own column; indexes violate this rule since the data values don't get their own column\n",
    "- In pandas, the syntax for working with indexes is different from the syntax for working with columns, making the code more complicated and introducing more bugs\n",
    "\n",
    "This is an example of a tidy table, taken from the paper, where each column defines a variable, each row contains an observation, and each type of observational unit forms a table.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "      <th>name</th>\n",
    "      <th>trt</th>\n",
    "      <th>result</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>John Smith</td>\n",
    "        <td>a</td>\n",
    "        <td style=\"text-align: right;\">-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Jane Doe</td>\n",
    "        <td>a</td>\n",
    "        <td style=\"text-align: right;\">16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Mary Johnson</td>\n",
    "        <td>a</td>\n",
    "        <td style=\"text-align: right;\">3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>John Smith</td>\n",
    "        <td>b</td>\n",
    "        <td style=\"text-align: right;\">2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Jane Doe</td>\n",
    "        <td>b</td>\n",
    "        <td style=\"text-align: right;\">11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Mary Johnson</td>\n",
    "        <td>b</td>\n",
    "        <td style=\"text-align: right;\">1</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b88b79-a34c-4cde-961d-c9b26da57a44",
   "metadata": {},
   "source": [
    "#### Setting and Removing Indexes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e478fa-ea72-4512-b540-22964afc9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out the exercise.\n",
    "print(temperatures)\n",
    "print()\n",
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index(\"city\")\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n",
    "print()\n",
    "# Reset the index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "print()\n",
    "# Reset the index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b7637-96e1-4b71-bc1c-b1a131b3d996",
   "metadata": {},
   "source": [
    "#### Subsetting with `.loc[]` (Exercise)\n",
    "\n",
    "With a good index, subsetting is easier using `.loc[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204b789-216e-45ae-b5b4-4efa2a42b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting two ways. The second DataFrame is indexed\n",
    "# by \"city\".\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "print()\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d9698-b77f-48bd-a322-b6bfdd82ba79",
   "metadata": {},
   "source": [
    "#### Setting Multi-Level Indexes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a65dd0-2a94-4d3c-9a43-641ff566f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index temperatures by country & city.\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "\n",
    "# Create a list of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep.\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16abb99f-7e7f-47c0-9fe8-4d2ef038fdce",
   "metadata": {},
   "source": [
    "#### Sorting by Index Values (Exercise)\n",
    "\n",
    "Use `.sort_values()` when sorting using columns; use `.sort_index()` when sorting using an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ff4c7-1eb0-4461-92df-c2e805f79e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "print()\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level=[\"city\"]))\n",
    "print()\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=[\"country\", \"city\"], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437401cb-32ee-4296-b4b4-0ef7e99e46a4",
   "metadata": {},
   "source": [
    "### Slicing and Subsetting with `.loc` and `.iloc`\n",
    "\n",
    "DataFrames can be sliced by index values or by row/column numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d637f4-fcaa-4901-ae63-15c913950547",
   "metadata": {},
   "source": [
    "#### Slicing a List (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7378f29-8cae-4a55-b404-83f850424553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice a list.\n",
    "breeds = [\"Labrador\", \"Poodle\", \"Chow Chow\", \"Schnauzer\", \"Labrador\", \"Chihuahua\", \"St. Bernard\"]\n",
    "print(breeds[2:5])\n",
    "print(breeds[:3])\n",
    "print(breeds[:])\n",
    "print(breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb9ae5-c8b0-4ef0-a72b-fb1b6b364bbb",
   "metadata": {},
   "source": [
    "#### Slice a DataFrame after Calling `.sort_index()` (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10426e56-9e82-46c6-8b81-fac292bc4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the dogs DataFrame.\n",
    "print(dogs)\n",
    "print()\n",
    "\n",
    "# There can be problems if you don't sort the index first.\n",
    "try:\n",
    "    print(dogs.set_index([\"breed\", \"color\"]).loc[\"Chow Chow\":\"Poodle\"])\n",
    "except Exception as ex:\n",
    "    print(\"Exception:\", ex)\n",
    "print()\n",
    "\n",
    "# Add an index and sort before slicing.\n",
    "dogs_srt = dogs.set_index([\"breed\", \"color\"]).sort_index()\n",
    "print(dogs_srt)\n",
    "print()\n",
    "# Slice using the outer level. The last item is included!\n",
    "print(dogs_srt.loc[\"Chow Chow\":\"Poodle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23b616-7e56-46cb-aa0c-7b2fb708982b",
   "metadata": {},
   "source": [
    "#### Slicing the Inner Index Levels Badly (Demonstration)\n",
    "\n",
    "Pandas does not raise an exception to let you know that you've done this incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af29b2a-239d-44e7-9ae1-9dea515f9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not work; it returns an empty DataFrame.\n",
    "print(dogs_srt.loc[\"Tan\":\"Gray\"])\n",
    "print()\n",
    "# To slice correctly, you must provide two tuples.\n",
    "print(dogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Gray\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1532d70-88ca-4593-9cb9-1539d839ac92",
   "metadata": {},
   "source": [
    "#### Slicing Columns (Demonstration)\n",
    "\n",
    "Since DataFrames are two-dimensional, you can also slice columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1fa54-081d-41f6-973a-6e2a94e889ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice columns.\n",
    "print(dogs_srt.loc[:, \"name\":\"height_cm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2c9d9-eb5c-4bd3-b044-f88db6ea9657",
   "metadata": {},
   "source": [
    "#### Slicing Rows and Columns at the Same Time (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba47b93-1d11-4885-9c13-312a333a93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice rows and columns.\n",
    "print(dogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Gray\"), \"name\":\"height_cm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc578b-ddc0-4468-a290-eda395438a99",
   "metadata": {},
   "source": [
    "#### Slicing Using a Range of Dates (Demonstration)\n",
    "\n",
    "An important use case for slicing is using a range of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d3e60-73fe-40cf-86e5-763386e80c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index and sort it.\n",
    "dogs_bd = dogs.set_index(\"date_of_birth\").sort_index()\n",
    "print(dogs_bd)\n",
    "print()\n",
    "# Slice the DataFrame by date of birth.\n",
    "print(dogs_bd.loc[\"2014-08-25\":\"2016-09-16\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b80d6-f801-440b-bd00-539a0508818f",
   "metadata": {},
   "source": [
    "#### Slice by Partial Dates (Demonstration)\n",
    "\n",
    "For this to work correctly, the column or index containing the dates must\n",
    "have dtype \"datetime64[ns]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd38540-b920-4103-b369-fa935599628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice by partial dates. \n",
    "print(dogs_bd.loc[\"2014\":\"2016\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fea5f8-09f1-4db4-a93d-e8912a3d58b3",
   "metadata": {},
   "source": [
    "#### Subsetting by Row or Column Number (Demonstration)\n",
    "\n",
    "Use the `.iloc[]` method for row and column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e275c-02da-47dd-816e-eb8c0a7039a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use row and column numbers to create a subset.\n",
    "print(dogs.iloc[2:5])\n",
    "print()\n",
    "print(dogs.iloc[:, 1:4])\n",
    "print()\n",
    "print(dogs.iloc[2:5, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba1787-c256-44fb-bfff-5d2949a63d6e",
   "metadata": {},
   "source": [
    "#### Slicing Index Values (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc212b54-77dd-4439-a6e8-25ff24319f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexed DataFrame for the exercise.\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "# Sort the index of temperatures_ind.\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "# Subset rows from Pakistan to Russia.\n",
    "print(temperatures_srt.loc[\"Pakistan\":\"Russia\"])\n",
    "# Try to subset rows from Lahore to Moscow. The results are not what\n",
    "# is wanted.\n",
    "print(temperatures_srt.loc[\"Lahore\":\"Moscow\"])\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow.\n",
    "print(temperatures_srt.loc[(\"Pakistan\", \"Lahore\"):(\"Russia\", \"Moscow\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d436d-3af4-4144-84c8-63e279f2d1b5",
   "metadata": {},
   "source": [
    "#### Slicing in Both Directions (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1343ba9-f8cc-410b-a105-6e427f471724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows from India, Hyderabad to Iraq, Baghdad.\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\n",
    "\n",
    "# Subset columns from date to avg_temp_c.\n",
    "print(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8a94c-4b39-48fa-b196-ef3e6188a1cb",
   "metadata": {},
   "source": [
    "### Working with Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0345523c-fd50-40d2-a319-8f221b62f3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fcd842e-292a-45c4-9963-169a9ac0e587",
   "metadata": {},
   "source": [
    "## Creating and Visualizing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22623a-fabc-4b58-a0b3-36c8c946cd43",
   "metadata": {},
   "source": [
    "### Visualizing Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5092b-5b89-4944-b7cd-e3ac3807851f",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5672ea-224d-4d69-baaa-f0617d6f7cd9",
   "metadata": {},
   "source": [
    "### Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372d3a6-5de9-4773-80d2-b173bb2722fd",
   "metadata": {},
   "source": [
    "### Reading and Writing CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa4f49-8866-4b30-8798-0b7a3791179f",
   "metadata": {},
   "source": [
    "### Wrap-Up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
