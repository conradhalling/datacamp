{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de970c6-14a9-4408-862f-b587d1e608f1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis in Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This course is written and presented by Allen Downey, Staff Scientist at DrivenData and Professor Emeritus at Olin College.\n",
    "\n",
    "This course covers much of the material covered by the Statistical Thinking in Python (Part 1) course.\n",
    "\n",
    "Prerequisite:\n",
    "- Python Data Science Toolbox (Part 2)\n",
    "\n",
    "This course is part of these tracks:\n",
    "- Data Analyst with Python (career track)\n",
    "- Data Scientist with Python (career track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c94d5-0e29-41aa-bb8e-2fb43ce6d0b1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Use the directions in the README.md file in the datacamp directory to set up the virtual environment for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9990b-a42f-43dd-9eab-6f6e10af881d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Imports are collected here for convenience and clarity.\n",
    "\n",
    "See the course \"Introduction to Importing Data in Python\", which uses the h5py module to load a .hdf5 file correctly.\n",
    "\n",
    "For this course, pytables (tables) is used as an alternative tool. See https://www.pytables.org/usersguide/introduction.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a30d7-0efd-42c2-9cb2-820822ddc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import empiricaldist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3bb74-d0c3-4018-88fa-412f5bb74211",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Name | File\n",
    "| :--- | :--- |\n",
    "| National Survey of Family Growth (NSFG) | nfsg.hdf5 |\n",
    "| General Social Survey (GSS) | gss.hdf5 |\n",
    "| Behavioral Risk Factor Surveillance System (BRFSS) | brfss.hdf5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6890c22-623b-42a4-a618-878639bbe085",
   "metadata": {},
   "source": [
    "### National Survey of Family Growth (NSFG)\n",
    "\n",
    "The data comes from the National Survey of Family Growth (NSFG) (https://www.cdc.gov/nchs/nsfg/index.htm) for 2013-2015. The survey is \"nationally representative of women 15-44 years of age in the ... United States.\" The data includes \"information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and general and reproductive health.\"\n",
    "\n",
    "It is necessary to read the codebook to understand the data fields. See, for example, https://www.cdc.gov/nchs/nsfg/nsfg_2013_2015_codebooks.htm.\n",
    "\n",
    "`birthwgt_lb1` stands for birth weight pounds. The values are:\n",
    "| value | label | total |\n",
    "| :--- | :--- | ---: |\n",
    "| - | INAPPLICABLE | 2673 |\n",
    "| 0-5 | UNDER 6 POUNDS | 936 |\n",
    "| 6 | 6 POUNDS | 1666 |\n",
    "| 7 | 7 POUNDS | 2146 |\n",
    "| 8 | 8 POUNDS | 1168 |\n",
    "| 9-95 | 9 POUNDS OR MORE | 474 |\n",
    "| 98 | Refused | 1 |\n",
    "| 99 | Don't know | 94 |\n",
    "\n",
    "`birthwgt_oz1` stands for birth weight ounces. The values are:\n",
    "| value | label | total |\n",
    "| :--- | :--- | ---: |\n",
    "| - | INAPPLICABLE | 2967 |\n",
    "| 0-15 | 0-15 OUNCES | 6355 |\n",
    "| 98 | Refused | 1 |\n",
    "| 99 | Don't know | 35 |\n",
    "\n",
    "`outcome` encodes the outcome of the pregnancy:\n",
    "| value | label |\n",
    "| :--- | :--- |\n",
    "| 1 | Live birth |\n",
    "| 2 | Induced abortion |\n",
    "| 3 | Stillbirth |\n",
    "| 4 | Miscarriage |\n",
    "| 5 | Ectopic pregnancy |\n",
    "| 6 | Current pregnancy |\n",
    "\n",
    "`nbrnaliv` records the number of babies born from the pregnancy:\n",
    "| value | label |\n",
    "| :--- | :--- |\n",
    "| . | INAPPLICABLE |\n",
    "| 1 | 1 BABY |\n",
    "| 2 | 2 BABIES |\n",
    "| 3 | 3 OR MORE BABIES |\n",
    "| 8 | Refused |\n",
    "\n",
    "#### Explore the HDFStore Object\n",
    "\n",
    "See https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b5ffd-b4d1-4e82-ac32-d89610ce35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HDFStore object and see what's inside.\n",
    "# The pandas DataFrame is available from\n",
    "# pd.HDFStore(\"nsfg.hdf5\", mode=\"r\").get(\"nsfg\").\n",
    "with pd.HDFStore(\"nsfg.hdf5\", mode=\"r\") as store:\n",
    "    print(type(store))\n",
    "    print()\n",
    "    print(store.info())\n",
    "    print()\n",
    "    print(store.keys())\n",
    "    print()\n",
    "    print(store.groups())\n",
    "    print()\n",
    "    \n",
    "    # Walk the group hierarchy (copied from the documentation).\n",
    "    # Somehow, the data is stored as a pandas DataFrame.\n",
    "    for (path, subgroups, subkeys) in store.walk():\n",
    "        for subgroup in subgroups:\n",
    "            print(\"GROUP: {}/{}\".format(path, subgroup))\n",
    "        for subkey in subkeys:\n",
    "            key = \"/\".join([path, subkey])\n",
    "            print(\"KEY: {}\".format(key))\n",
    "            print()\n",
    "            data = store.get(key)\n",
    "            print(type(data))\n",
    "            print()\n",
    "            print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eacee54-9afb-4181-949c-e34e576e5409",
   "metadata": {},
   "source": [
    "#### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3918eb-14b8-437f-8075-ec356f2d418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file using the \"nsfg\" key.\n",
    "nsfg = pd.read_hdf(\"nsfg.hdf5\", \"nsfg\")\n",
    "print(type(nsfg))\n",
    "print()\n",
    "print(nsfg.info())\n",
    "print()\n",
    "print(nsfg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88fbfd-79b9-4ff7-adbd-4c2f4260b85f",
   "metadata": {},
   "source": [
    "### General Social Survey (GSS)\n",
    "\n",
    "The General Social Survey (GSS) is an annual sample of the U.S. population recording hundreds of variables. The survey asks about demographic, social, and political beliefs. The data are widely used by politicians, policy makers, and researchers. Allen Downey has selected a few of the variables, cleaned and validated the data, and packaged the data into the gss.hdf5 file.\n",
    "\n",
    "#### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21a2be-a89d-4c34-8d6e-9aa80faee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a DataFrame using the key \"gss\".\n",
    "gss = pd.read_hdf(\"gss.hdf5\", \"gss\")\n",
    "print(gss.info())\n",
    "print()\n",
    "print(gss.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e327c25-987d-4448-beca-25765b0f0ec4",
   "metadata": {},
   "source": [
    "### Behavioral Risk Factor Surveillance System (BRFSS)\n",
    "\n",
    "#### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244304b9-a8fb-45b1-96df-7ca475f01b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a DataFrame using the key \"brfss\".\n",
    "brfss = pd.read_hdf(\"brfss.hdf5\", \"brfss\")\n",
    "print(brfss.info())\n",
    "print()\n",
    "print(brfss.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5131d60-24a8-4133-ae23-450980827134",
   "metadata": {},
   "source": [
    "## Read, Clean, and Validate\n",
    "\n",
    "### DataFrames and Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057622fd-3fb4-4999-b264-ed1f57876915",
   "metadata": {},
   "source": [
    "#### Reading Data (Example)\n",
    "\n",
    "The data has been read into the `nsfg` variable, which is a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85753a9a-ef41-4cba-8b51-e6da75037db4",
   "metadata": {},
   "source": [
    "#### Read the Codebook (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73578d-7f99-48f1-95b6-8a7d73cf00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column is a pandas Series.\n",
    "# NaN is used to indicate invalid or missing data.\n",
    "pounds = nsfg[\"birthwgt_lb1\"]\n",
    "print(type(pounds))\n",
    "print()\n",
    "print(pounds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a036aa-4f29-40e0-bb1d-e5d8741c745f",
   "metadata": {},
   "source": [
    "#### Exploring the NSFG Data (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79afcd-1ba8-4d4d-83ce-8b7833642b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of rows and columns.\n",
    "print(nsfg.shape)\n",
    "# Display the names of the columns.\n",
    "print(nsfg.columns)\n",
    "# Select column birthwgt_oz1: ounces.\n",
    "ounces = nsfg['birthwgt_oz1']\n",
    "# Print the first 5 elements of ounces.\n",
    "print(ounces.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9515203-4e33-4268-bde9-57b3b25f0b50",
   "metadata": {},
   "source": [
    "### Clean and Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be936e-5853-4de2-90c3-2189478ea8d1",
   "metadata": {},
   "source": [
    "#### Selecting Columns (Example)\n",
    "\n",
    "We reuse the pounds and ounces variables created above.\n",
    "\n",
    "#### Validating Data (Example)\n",
    "\n",
    "We can validate the numbers by comparing them to the codebook values (see above). \"The results agree with the codebook, so we have some confidence that we are reading and interpreting the data correctly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d3b4a-cc33-4a30-b66b-1391b6c4155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can start validating the data by counting the distinct values, which\n",
    "# creates a pandas Series ordered by the counts.\n",
    "pounds_counts = pounds.value_counts()\n",
    "print(type(pounds_counts))\n",
    "print(pounds_counts)\n",
    "print()\n",
    "\n",
    "# Sort the data by the index, the number of pounds.\n",
    "sorted_pounds_counts = pounds_counts.sort_index()\n",
    "print(type(sorted_pounds_counts))\n",
    "print(sorted_pounds_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649050a5-0c09-4c45-b2cd-08f52666d514",
   "metadata": {},
   "source": [
    "#### Validate using Describe (Example)\n",
    "\n",
    "Another way to validate the data is to use the `.describe()` method of the pandas Series object to create summary statistics. The mean is distorted by the special values of 98 and 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fad23-90c1-44e3-873f-45188e8554b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics.\n",
    "print(pounds.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc90c3-ec90-4d6d-a9f9-876e0023e0b9",
   "metadata": {},
   "source": [
    "#### Replace Bad Data (Example)\n",
    "\n",
    "Replace values of 98 and 99, which indicate missing data, with NaN. The summary statistics exclude rows with NaN. The code shows two ways to replace data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d072b7-b6ea-43aa-811c-c42a6dd6c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values of 98 and 99 with np.nan.\n",
    "pounds = pounds.replace([98, 99], np.nan)\n",
    "print(pounds.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c10d70-599c-4ff7-a8de-8146b1424a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ounces.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104c284-9279-4e1f-9430-c9e4995add96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ounces.replace([98, 99], np.nan, inplace=True)\n",
    "print(ounces.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cac03c-2755-444f-8401-930cf706f400",
   "metadata": {},
   "source": [
    "#### Calculate a New Column Using Series Arithmetic (Example)\n",
    "\n",
    "Combine pounds and ounces into a combined value, which could have units of pounds, ounces, or another mass unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fea7e-4913-4887-b823-0c9589e21fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pounds and ounces into a new birth_weight series.\n",
    "birth_weight = pounds + ounces / 16\n",
    "print(birth_weight.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09d891-9f86-4342-afc9-7da5254f1bf1",
   "metadata": {},
   "source": [
    "#### Validate a Variable (Exercise)\n",
    "\n",
    "According to the codebook (see above), the outcome column contains 1 for a live birth. How many live births occurred in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472e20c-095a-4401-95dc-227df3dbb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of live births (6,489).\n",
    "print(nsfg[\"outcome\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd503d5-c6d6-4ea2-bfc5-b8d3c90d5142",
   "metadata": {},
   "source": [
    "#### Clean a Variable (Exercise)\n",
    "\n",
    "Replace the nbrnaliv value of 8 with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14873416-bad7-44ed-83c6-c7cb56b68d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 8 to NaN in place.\n",
    "print(\"Before:\")\n",
    "print(nsfg[\"nbrnaliv\"].info())\n",
    "print()\n",
    "print(nsfg[\"nbrnaliv\"].value_counts().sort_index())\n",
    "print()\n",
    "print(\"After:\")\n",
    "nsfg[\"nbrnaliv\"].replace(8, np.nan, inplace=True)\n",
    "print(nsfg[\"nbrnaliv\"].info())\n",
    "print(nsfg[\"nbrnaliv\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff609a9-b41b-4368-8e98-f1a936e75b95",
   "metadata": {},
   "source": [
    "#### Compute a Variable (Exercise)\n",
    "\n",
    "The agecon and agepreg variable contain the age at conception and the age at the end of pregnancy multiplied by 100. Create new variables by dividing these values by 100. Calculate the length of the pregnancy (in years). Calculating a new variable is sometimes called a \"recode\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef5cbf-3694-4275-8626-826417595e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of agecon and agepreg in years.\n",
    "# Compute the difference.\n",
    "agecon = nsfg[\"agecon\"] / 100\n",
    "agepreg = nsfg[\"agepreg\"] / 100\n",
    "preg_length = agepreg - agecon\n",
    "print(preg_length.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ddc84-7ef7-4d15-858b-0c826f090353",
   "metadata": {},
   "source": [
    "### Filter and Visualize\n",
    "\n",
    "#### Create a Histogram of Birth Weights (Example)\n",
    "\n",
    "\"There are more light babies than heavy babies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e91983-0cb4-4aab-aa62-f3cf8f624124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram from the birth_weight variable.\n",
    "# I applied what I learned from the \"Introduction to Data Visualization with\n",
    "# Matplotlib\" and \"Statistical Thinking in Python\" courses here.\n",
    "# bins is set up at 1/4-pound intervals.\n",
    "# Allen applied the .dropna() method to the birth_weight variable.\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((12, 8))\n",
    "bins = np.linspace(0, 18, 73)\n",
    "_ = plt.hist(birth_weight.dropna(), bins=bins)\n",
    "_ = plt.xlabel(\"Birth weight (pounds)\")\n",
    "_ = plt.xticks(np.arange(0, 19))\n",
    "_ = plt.ylabel(\"Number of births\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec68ad8-09ca-42ac-98ff-688f5f361750",
   "metadata": {},
   "source": [
    "#### Filter Preterm Births (Example)\n",
    "\n",
    "Preterm babies are babies born less than 37 weeks after conception. We can filter for these using the prglngth column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ffbd4-ed5c-495d-81bf-fe6571834cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and count preterm births. True = 1; False = 0.\n",
    "preterm = nsfg[\"prglngth\"] < 37\n",
    "print(preterm.head())\n",
    "# Count the number of preterm births.\n",
    "print(preterm.sum())\n",
    "# Calculate the proportion of preterm births.\n",
    "print(preterm.mean())\n",
    "# Get info about preterm.\n",
    "print(preterm.info())\n",
    "# And summary statistics.\n",
    "print(preterm.describe())\n",
    "# Count True and False values.\n",
    "print(preterm.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf3317-858b-4d47-8e2b-cea4ef44642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the birth weights for preterm babies.\n",
    "preterm_weight = birth_weight[preterm == True]\n",
    "# Alternative formula:\n",
    "# preterm_weight = birth_weight[preterm]\n",
    "print(preterm_weight.mean())\n",
    "fullterm_weight = birth_weight[preterm == False]\n",
    "# Alternative formula:\n",
    "# fullterm_weight = birth_weight[~preterm]\n",
    "print(fullterm_weight.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44c418-b2aa-4fd0-9c22-cab4761434a9",
   "metadata": {},
   "source": [
    "#### Plot Histograms of Preterm and Fullterm Births (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffebb4-66a6-41b9-8342-278043fe7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((12, 8))\n",
    "bins = np.linspace(0, 18, 73)\n",
    "alpha = 0.4\n",
    "_ = plt.hist(birth_weight.dropna()[preterm], bins=bins,\n",
    "             label=\"Preterm births\", alpha=alpha)\n",
    "_ = plt.hist(birth_weight.dropna()[~preterm], bins=bins,\n",
    "             label=\"Fullterm births\", alpha=alpha)\n",
    "_ = plt.xlabel(\"Birth weight (pounds)\")\n",
    "_ = plt.xticks(np.arange(0, 19))\n",
    "_ = plt.ylabel(\"Number of births\")\n",
    "_ = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79faf2f0-5f9a-4805-8019-e70abba28fe8",
   "metadata": {},
   "source": [
    "#### Resampling (Example)\n",
    "\n",
    "The NSFG is not representative of the U.S. population; some groups are oversampled. Oversampling makes sure you have enough people in some subgroups to perform a reliable statistical analysis. We can correct using Allen's `resample_rows_weighted()` function. I obtained the code for that function from the DataCamp console using `??resample_rows_weight`.\n",
    "\n",
    "```Python\n",
    "def resample_rows_weighted(df, column='finalwgt', seed=17):\n",
    "    \"\"\"Resamples a DataFrame using probabilities proportional to given column.\n",
    "\n",
    "    df: DataFrame\n",
    "    column: string column name to use as weights\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    weights = df[column] / sum(df[column])\n",
    "    indices = np.random.choice(df.index, len(df), replace=True, p=weights)\n",
    "    sample = df.loc[indices]\n",
    "    return sample\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f82dd4-2fd4-47a6-b469-c2c755172a55",
   "metadata": {},
   "source": [
    "#### Create a Histogram of Age at Conception (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a26ece-4c8c-4218-870a-70ba5407fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(agecon, bins=20, histtype=\"step\")\n",
    "plt.xlabel('Age at conception')\n",
    "plt.ylabel('Number of pregnancies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2988f-9c9e-4976-b7cc-d6c5034c6b92",
   "metadata": {},
   "source": [
    "#### Resample the Data (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e1609-d8e7-4ae9-b360-8834d03cb12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to make it more representative using the weight\n",
    "# values in the \"wgt2013_2015\" column.\n",
    "# This code was provided.\n",
    "def resample_rows_weighted(df, column, seed=17):\n",
    "    \"\"\"Resample a DataFrame using probabilities proportional to given column.\n",
    "\n",
    "    df: DataFrame\n",
    "    column: string column name to use as weights\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    weights = df[column] / sum(df[column])\n",
    "    indices = np.random.choice(df.index, len(df), replace=True, p=weights)\n",
    "    sample = df.loc[indices]\n",
    "    return sample\n",
    "\n",
    "# Resample the data.\n",
    "nsfg2 = resample_rows_weighted(nsfg, 'wgt2013_2015')\n",
    "# Clean the weight variables.\n",
    "pounds2 = nsfg2['birthwgt_lb1'].replace([98, 99], np.nan)\n",
    "ounces2 = nsfg2['birthwgt_oz1'].replace([98, 99], np.nan)\n",
    "# Compute total birth weight\n",
    "birth_weight2 = pounds2 + ounces2 / 16\n",
    "birth_weight2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b3971-2071-452d-a1f8-157636cbe617",
   "metadata": {},
   "source": [
    "#### Compute Mean Birth Weight (Exercise)\n",
    "\n",
    "Using nsfg2, the resampled data, as a data source, compute the birth weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c0b0d-ef88-4b78-8d9b-727aeea6fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Boolean Series for full-term babies\n",
    "full_term = nsfg2[\"prglngth\"] >= 37\n",
    "\n",
    "# Select the weights of full-term babies\n",
    "full_term_weight = birth_weight2[full_term]\n",
    "\n",
    "# Compute the mean weight of full-term babies\n",
    "print(full_term_weight.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a93a2-a7a2-47d1-946d-fd45af54f7e8",
   "metadata": {},
   "source": [
    "#### Filter out Multiple Births (Exercise)\n",
    "\n",
    "Some pregnancies lead to multiple births. Filter these out since the distribution of birth weight is different for twins, triplets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c1689-3667-4586-89c4-2dfbcaead4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter single births.\n",
    "single = nsfg2[\"nbrnaliv\"] == 1\n",
    "# Compute birth weight for single full-term babies.\n",
    "single_full_term_weight = birth_weight2[full_term & single]\n",
    "print('Single full-term mean:', single_full_term_weight.mean())\n",
    "# Compute birth weight for multiple full-term babies\n",
    "mult_full_term_weight = birth_weight2[full_term & ~single]\n",
    "print('Multiple full-term mean:', mult_full_term_weight.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c3601-f222-4bcb-8426-94237144e857",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "### Probability Mass Functions\n",
    "\n",
    "The code makes use of Allen Downey's empiricaldist module, which is documented here: https://nbviewer.org/github/AllenDowney/empiricaldist/blob/master/empiricaldist/dist_demo.ipynb. By default, the probabilities are normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe81f8-e79d-49ce-9d68-0fcaa33c43d1",
   "metadata": {},
   "source": [
    "#### Plot a Histogram of Years of Education (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a4006-1266-4914-afd1-bc0020857879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable containing the number of years of education.\n",
    "# Create a histogram of the data.\n",
    "# Create a bin for each year of education.\n",
    "educ = gss[\"educ\"]\n",
    "plt.hist(educ.dropna(), bins=np.arange(0, 22), label=\"educ\")\n",
    "plt.xticks(np.arange(0, 23, 2))\n",
    "plt.xlabel(\"Years of education\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79cc37-e1cc-4076-8eb9-960a841c8193",
   "metadata": {},
   "source": [
    "#### Create a PMF of Years of Education (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee7623-fa7f-42b2-8b96-edc342ae313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API has changed; call empiricaldist.Pmf.from_seq(),\n",
    "# not empiricaldist.Pmf() as shown in the demonstration.\n",
    "# The dataset used in the course's video is different from the one\n",
    "# delivered by the course.\n",
    "pmf_educ = empiricaldist.Pmf.from_seq(educ, normalize=False)\n",
    "print(pmf_educ)\n",
    "print(pmf_educ[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d58f7e-962f-4126-b216-284393f5e644",
   "metadata": {},
   "source": [
    "#### Create a Normalized PMF of Years of Education (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc83cd3-43be-4ade-859e-3b8e7dc621cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the PMF.\n",
    "pmf_educ2 = empiricaldist.Pmf.from_seq(educ, normalize=True)\n",
    "print(pmf_educ2)\n",
    "print(pmf_educ2[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e2351-3976-4e56-a1bc-a9a844bc43dd",
   "metadata": {},
   "source": [
    "#### Plot the PMF of Years of Education (Demonstration)\n",
    "\n",
    "As expected, the bar chart is similar to the histogram. There are peaks at 12, 14, and 16 years, which correspond to completing high school, two years of colleage, and four years of college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447aaf9-180a-4837-88e5-29c2e8053c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart of the PMF.\n",
    "pmf_educ2.bar(label=\"educ\")\n",
    "plt.xlabel(\"Years of education\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9744e2-ab43-43c7-86c9-3593f36a9b5f",
   "metadata": {},
   "source": [
    "#### Create a PMF of the Data in the year Column (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc87ac5-7c75-45a5-bced-9ffcb0d41723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PMF.\n",
    "pmf_year = empiricaldist.Pmf.from_seq(gss[\"year\"], normalize=False)\n",
    "print(pmf_year)\n",
    "# 2,867 people were interviewed in 2016.\n",
    "print(pmf_year[2016])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276552bb-bf78-4dd5-92fd-e436cd58a829",
   "metadata": {},
   "source": [
    "#### Create a PMF of the Data in the age Column (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62188f-9b7a-41c0-bcde-0611708ee04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot the PMF of the data in the age column.\n",
    "# The Pmf object has a method named .bar() that calls \n",
    "# matplotlib.pyplot.bar().\n",
    "age = gss['age']\n",
    "pmf_age = empiricaldist.Pmf.from_seq(age)\n",
    "pmf_age.bar()\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('PMF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9352f7-389f-47d8-adf4-157ad63eaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively:\n",
    "# qs is quantities, ps is probabilities.\n",
    "plt.bar(pmf_age.qs, pmf_age.ps)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b1e25-f0bf-42fc-b94e-6ee7cc59d4fc",
   "metadata": {},
   "source": [
    "### Cumulative Distribution Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4080aaa9-243c-4626-aa8c-1cd9b2e74a80",
   "metadata": {},
   "source": [
    "#### From PMF to CDF (Example)\n",
    "\n",
    "For discrete random variables, the PMF (probability mass function) returns the probability that you get exactly x for a given value of x. The CDF returns the probability that you get a value less than or equal to x for a given value of x.\n",
    "\n",
    "Using the empiricaldist module's Cdf class, we can calculate and plot the CDF.\n",
    "\n",
    "See also the \"Statistical Thinking in Python (Part 1)\" course, which shows how to calculate the empirical CDF.\n",
    "\n",
    "The PMF and CDF plots look like the uniform distribution up to about age 45, after which sample ages are less frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bc9d6-d23d-4b7f-8fbe-09efef2cdfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the CDF.\n",
    "# Call empiricaldist.Cdf.from_seq() to calculate the CDF correctly.\n",
    "\n",
    "cdf = empiricaldist.Cdf.from_seq(gss[\"age\"])\n",
    "print(type(cdf))\n",
    "_ = cdf.plot()\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.show()\n",
    "\n",
    "# Get the empirical CDF for given age.\n",
    "q = 51\n",
    "p = cdf(q)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3e4a3-9438-4ddd-b781-ee4071976f21",
   "metadata": {},
   "source": [
    "#### Evaluating the Inverse CDF (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805caf53-c4fa-417e-b7a8-70827633463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the age at which the CDF is a given value.\n",
    "# The interquartile range (IQR), a measure of the spread of the data,\n",
    "# is 30-57. The median age is 43.\n",
    "probabilities = (0.25, 0.50, 0.75)\n",
    "for p in probabilities:\n",
    "    print(\"{}: {}\".format(p, cdf.inverse(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57628cd1-aa70-4df0-819e-41d8a44cab89",
   "metadata": {},
   "source": [
    "#### Make and Use a CDF (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010d5a1-4a07-4050-80cc-8a6da7200faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CDF and use it to calculate the proportion of ages > 30.\n",
    "cdf_age = empiricaldist.Cdf.from_seq(gss[\"age\"])\n",
    "prop = 1 - cdf_age(30)\n",
    "print(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f8dbb-cb86-4f3a-924b-65b2c6c763e1",
   "metadata": {},
   "source": [
    "#### Compute IQR (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84369deb-1534-48b8-b09a-be3a7292ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR for income.\n",
    "cdf_income = empiricaldist.Cdf.from_seq(gss[\"realinc\"])\n",
    "percentile_75th = cdf_income.inverse(0.75)\n",
    "percentile_25th = cdf_income.inverse(0.25)\n",
    "iqr = percentile_75th - percentile_25th\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f98a78-21a6-4404-9a5b-51dc29bf73fa",
   "metadata": {},
   "source": [
    "#### Plot a CDF (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284dfb8f-88d1-40ec-a4aa-e20d6f0ac9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot the CDF for realinc.\n",
    "income = gss[\"realinc\"]\n",
    "cdf_income = empiricaldist.Cdf.from_seq(income)\n",
    "cdf_income.plot()\n",
    "plt.xlabel('Income (1986 USD)')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c4661-01d4-4d7a-8d7b-25c785128f31",
   "metadata": {},
   "source": [
    "### Comparing Distributions\n",
    "\n",
    "In general, CDFs are smoother than PMFs.\n",
    "\n",
    "#### Compare Multiple PMFs (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b79d2d-1a9e-48ee-8760-4d0dd9450dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the PMFs for age for males and females.\n",
    "male = gss[\"sex\"] == 1\n",
    "age = gss[\"age\"]\n",
    "male_age = age[male]\n",
    "# Use the bitwise ~ (not) operator here. \"not male\" does not work.\n",
    "# female_age = age[~male]\n",
    "female_age = age[np.logical_not(male)]\n",
    "# Using a bar plot obscures the overlapping bars.\n",
    "# Using a line plot is clearer.\n",
    "# empiricaldist.Pmf.from_seq(male_age).bar(label=\"Male\")\n",
    "# empiricaldist.Pmf.from_seq(female_age).bar(label=\"Female\")\n",
    "empiricaldist.Pmf.from_seq(male_age).plot(label=\"Male\")\n",
    "empiricaldist.Pmf.from_seq(female_age).plot(label=\"Female\")\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f1ae0-96d6-4639-b05e-29d37c556ae1",
   "metadata": {},
   "source": [
    "#### Determine Equality of two Pandas Series (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c95513-09b0-4d33-85b9-1631878b0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine equality of two Pandas series:\n",
    "female_age1 = age[np.logical_not(male)]\n",
    "female_age2 = age[~male]\n",
    "print(female_age1.equals(female_age2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e5f3f-e695-4a61-b13d-793f89c75a92",
   "metadata": {},
   "source": [
    "#### Compare Multiple CDFs (Example)\n",
    "\n",
    "In this example, the line for \"Male\" is slightly to the left of the line for \"Female\". This means there were more males than females at or below the given age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49176f-902e-42ca-9cc2-c3a75c5a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the age CDFs for males and females.\n",
    "male_cdf = empiricaldist.Cdf.from_seq(male_age).plot(label=\"Male\")\n",
    "female_cdf = empiricaldist.Cdf.from_seq(female_age).plot(label=\"Female\")\n",
    "plt.xlabel(\"Age (years)\")\n",
    "plt.ylabel(\"Cumulative probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb6e21-efe5-4117-8fab-cdfcea975fcc",
   "metadata": {},
   "source": [
    "#### Compare Household Income before and after 1995 (Example)\n",
    "\n",
    "1995 is the midpoint of the survey. The `realinc` variable represents household income in 1986 dollars. The `year` column provides the year of the interview.\n",
    "\n",
    "> There are a lot of unique values in this distribution, and none of them appear very often. The PMF is so noisy, we can't really see the shape of the distribution. It looks like there are more people with high incomes after 1995, but it's hard to tell.\n",
    "\n",
    "> Below $30,000 the CDFs are almost identical; above that, we can see that the 1995 and after distribution is shifted to the right. In other words, the fraction of people with high incomes is about the same, but the income of high earners has increased.\n",
    "\n",
    "In general, Allen Downey recommends using CDFs to compare distributions because they give a clear view of the distribution without as much noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c2e51-16ad-4bb2-a173-aa26ca789d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot realinc before 1995 to realinc at or after 1995.\n",
    "income = gss[\"realinc\"]\n",
    "pre95 = gss[\"year\"] < 1995\n",
    "alpha = 0.6\n",
    "empiricaldist.Pmf.from_seq(income[pre95]).plot(label=\"Before 1995\", alpha=alpha)\n",
    "empiricaldist.Pmf.from_seq(income[np.logical_not(pre95)]).plot(label=\"1995 and after\", alpha=alpha)\n",
    "plt.xlabel(\"Income (1986 USD)\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe78b0-7f64-4caa-9524-81623d0ef1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using CDF plots.\n",
    "# Plot realinc before 1995 to realinc at or after 1995.\n",
    "empiricaldist.Cdf.from_seq(income[pre95]).plot(label=\"Before 1995\", alpha=alpha)\n",
    "empiricaldist.Cdf.from_seq(income[np.logical_not(pre95)]).plot(label=\"1995 and after\", alpha=alpha)\n",
    "plt.xlabel(\"Income (1986 USD)\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5edbce-a3d6-4a80-a050-38dc564e7e44",
   "metadata": {},
   "source": [
    "#### Distribution of Education (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1ead4-8809-4c67-aa19-710027db03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What fraction of respondents reported 12 years of education or less?\n",
    "# I had to call .dropna() to get the result for the next exercise to match\n",
    "# the result from this exercise.\n",
    "educ = gss[\"educ\"].dropna()\n",
    "educ_cdf = empiricaldist.Cdf.from_seq(educ)\n",
    "print(educ_cdf(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03188f64-3d78-4b2e-8ea3-e51027af6182",
   "metadata": {},
   "source": [
    "#### Extract Education Levels (Exercise)\n",
    "\n",
    "Create boolean filters for different education levels. Find the fraction of respondents who reported 12 years of education or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436c93a-8b5c-4c9f-8af0-118db00e73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelor's degree\n",
    "bach = (educ >= 16)\n",
    "# Associate degree\n",
    "assc = ((educ >= 14) & (educ < 16))\n",
    "# High school (12 or fewer years of education)\n",
    "high = (educ <= 12)\n",
    "print(high.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ad52-6024-4e37-9b45-91731b71e09e",
   "metadata": {},
   "source": [
    "#### Plot Income CDFs (Exercise)\n",
    "\n",
    "Compare incomes for different education levels. The CDFs show that people with more education had higher incomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78dc6b2-7f5c-43df-b49f-98d076234d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain new Series objects without calling .dropna(), because\n",
    "# this causes length mismatches.\n",
    "educ = gss[\"educ\"]\n",
    "bach = (educ >= 16)\n",
    "assc = ((educ >= 14) & (educ < 16))\n",
    "high = (educ <= 12)\n",
    "\n",
    "income = gss[\"realinc\"]\n",
    "empiricaldist.Cdf.from_seq(income[high]).plot(label=\"High School\")\n",
    "empiricaldist.Cdf.from_seq(income[assc]).plot(label=\"Associate\")\n",
    "empiricaldist.Cdf.from_seq(income[bach]).plot(label=\"Bachelor\")\n",
    "plt.xlabel(\"Income (1986 USD\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f707f-e163-4277-88cc-849f3bd1c851",
   "metadata": {},
   "source": [
    "#### Compare Incomes for Education Levels (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dada7d6-14b3-4ec6-b10e-03c9f6361590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat this analysis with more education levels.\n",
    "scol = educ == 13\n",
    "bach = educ == 16\n",
    "advc = educ > 16\n",
    "empiricaldist.Cdf.from_seq(income[high]).plot(label=\"High School\")\n",
    "empiricaldist.Cdf.from_seq(income[scol]).plot(label=\"Some College\")\n",
    "empiricaldist.Cdf.from_seq(income[assc]).plot(label=\"Associate\")\n",
    "empiricaldist.Cdf.from_seq(income[bach]).plot(label=\"Bachelor\")\n",
    "empiricaldist.Cdf.from_seq(income[advc]).plot(label=\"Advanced\")\n",
    "plt.xlabel(\"Income (1986 USD\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Print median incomes for the extreme education levels.\n",
    "print(\"High School:\", empiricaldist.Cdf.from_seq(income[high]).inverse(0.5))\n",
    "print(\"Advanced:\", empiricaldist.Cdf.from_seq(income[advc]).inverse(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a897e-384a-4ab2-80f4-2a2e6331202c",
   "metadata": {},
   "source": [
    "### Modeling Distributions\n",
    "\n",
    "#### CDF of the Normal Distribution (Example)\n",
    "\n",
    "Use a pseudorandom number generator for the normal distribution to create 1000 sample values. Create and plot the CDF of the random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2c102-4a98-4cb6-8c86-0233c5f75031",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "sample = rng.normal(size=1000)\n",
    "ecdf = empiricaldist.Cdf.from_seq(sample)\n",
    "ecdf.plot()\n",
    "plt.xlabel(\"Random value\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.xticks(np.arange(-4, 5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28adabd-2589-464d-9d7c-0b33cabd5570",
   "metadata": {},
   "source": [
    "`scipy.stats.norm` is an object that represents the normal distribution. A CDF created by scipy overlaps the CDF created by Numpy. If this were real data, we would conclude that the normal distribution was a good model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e586285-21b3-4b24-8947-7e585f90d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CDF from the normal distribution with mean 0 and standard\n",
    "# deviation 1.\n",
    "# Plot the two CDS.\n",
    "alpha = 0.4\n",
    "ecdf.plot(alpha=alpha, label=\"Numpy\")\n",
    "xs = np.linspace(-3, 3)\n",
    "ys = scipy.stats.norm(0, 1).cdf(xs)\n",
    "plt.plot(xs, ys, alpha=alpha, label=\"Scipy\")\n",
    "plt.xlabel(\"Random value\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690b84a-3a3c-4581-8684-8c043114b661",
   "metadata": {},
   "source": [
    "#### The PDF of the Normal Distribution (the Bell Curve) (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188ec83-a72b-46c1-9fb6-7dcfa46883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = scipy.stats.norm(0, 1).pdf(xs)\n",
    "plt.plot(xs, ys, color=\"gray\")\n",
    "plt.xlabel(\"Normal random value\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a621f2fc-90e8-447e-9e29-d79cfee3b04d",
   "metadata": {},
   "source": [
    "#### Compare PDF to PMF for the Normal Distribution (Example)\n",
    "\n",
    "This doesn't work well. The 1000 random samples all have unique values, so the probability of each sample is 1/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555336a-d345-4f81-a3bf-fc4e2a24e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "empiricaldist.Pmf.from_seq(sample).plot(label=\"Numpy\")\n",
    "plt.plot(xs, ys, label=\"Scipy\")\n",
    "plt.xlabel(\"Random value\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cac280-3e67-48ee-b20f-fbea1e7db3d7",
   "metadata": {},
   "source": [
    "#### Kernel Density Estimation (KDE) (Example)\n",
    "\n",
    "Kernel density estimation (KDE) is\n",
    "> a way of getting from a PMF, a probability mass function, to a PDF, a probability density function.\n",
    "\n",
    "> To generate a KDE plot, we'll use the Seaborn library for data visualization, which I import as sns. Seaborn provides kdeplot, which takes the sample, estimates the PDF, and plots it. Here's what it looks like.\n",
    "\n",
    "> he KDE plot matches the normal PDF pretty well, although the differences look bigger when we compare PDFs than they did with the CDFs. On one hand, that means that the PDF is a more sensitive way to look for differences, but often it is too sensitive. It's hard to tell whether apparent differences mean anything, or if they are just random, as in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab95d9-dd7f-4a22-b980-df24a8a7e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KDE plot.\n",
    "sns.kdeplot(sample, label=\"Numpy + KDE\")\n",
    "plt.plot(xs, ys, label=\"Scipy\")\n",
    "plt.xlabel(\"Random value\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98213ea2-4626-4225-9463-d3193015b080",
   "metadata": {},
   "source": [
    "#### Distribution of Income (Exercise)\n",
    "\n",
    "> In many datasets, the distribution of income is approximately lognormal, which means that the logarithms of the incomes fit a normal distribution. We'll see whether that's true for the GSS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf46e75-7354-4dbc-a8cb-d9e07acdd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract realinc and compute its log.\n",
    "# Find the mean and standard deviation.\n",
    "income = gss['realinc']\n",
    "log_income = np.log10(income)\n",
    "mean = log_income.mean()\n",
    "std = log_income.std()\n",
    "print(mean, std)\n",
    "dist = scipy.stats.norm(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f03911-6ab7-48f5-9ca3-9c7ea07971a1",
   "metadata": {},
   "source": [
    "#### Comparing CDFs (Exercise)\n",
    "\n",
    "> To see whether the distribution of income is well modeled by a lognormal distribution, we'll compare the CDF of the logarithm of the data to a normal distribution with the same mean and standard deviation.\n",
    "\n",
    "> The lognormal model is a pretty good fit for the data, but clearly not a perfect match. That's what real data is like; sometimes it doesn't fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38561aaa-d5fd-4abb-af77-17fdae814d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the model CDF to the observed CDF.\n",
    "xs = np.linspace(2, 5.5, 71) # 50 xs by default\n",
    "# print(xs)\n",
    "ys = dist.cdf(xs)\n",
    "plt.plot(xs, ys, label=\"Scipy\")\n",
    "empiricaldist.Cdf.from_seq(log_income).plot(label=\"GSS\")\n",
    "plt.xlabel('log10 of realinc')\n",
    "plt.ylabel('CDF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5397f2-ab9a-459a-8acb-8605b653f049",
   "metadata": {},
   "source": [
    "#### Comparing PDFs (Exercise)\n",
    "\n",
    "Compare a PDF (probability distribution function) and a KDE (kernel density estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecf27c-a53f-47de-90b3-1a7fb15ee147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot the model PDF.\n",
    "xs = np.linspace(2, 5.5, 71)\n",
    "ys = dist.pdf(xs)\n",
    "plt.plot(xs, ys, label=\"Scipy\")\n",
    "# Plot the data KDE.\n",
    "sns.kdeplot(log_income, label=\"GSS\")\n",
    "plt.xlabel(\"Log10(realinc)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7288b-3959-486f-ae28-5e321ce4abea",
   "metadata": {},
   "source": [
    "## Relationships\n",
    "\n",
    "### Exploring Relationships\n",
    "\n",
    "### Visualizing Relationships\n",
    "\n",
    "### Correlation\n",
    "\n",
    "### Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451b1fb-d959-4cfd-b610-6b0a8c237daf",
   "metadata": {},
   "source": [
    "## Multivariate Thinking\n",
    "\n",
    "### Limits of Simple Regression\n",
    "\n",
    "### Multiple Regression\n",
    "\n",
    "### Visualizing Regression Results\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2380221-5ca4-478e-9909-8a6dfe1c4f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
