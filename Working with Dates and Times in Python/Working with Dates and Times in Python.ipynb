{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1304d864-ac54-4ede-9065-34bf7339dcab",
   "metadata": {},
   "source": [
    "# Working with Dates and Times in Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "These are my notes for DataCamp's course [_Working with Dates and Times in Python_](https://www.datacamp.com/courses/working-with-dates-and-times-in-python).\n",
    "\n",
    "This course is presented by Max Shron, data scientist and author. Collaborators are Chester Ismay and Sumedh Panchadhar.\n",
    "\n",
    "Prerequisite:\n",
    "\n",
    "- [_Data Manipulation with Pandas_](../Data%20Manipulation%20with%20Pandas/Data%20Manipulation%20with%20Pandas.ipynb)\n",
    "\n",
    "This course is part of these tracks:\n",
    "\n",
    "- Data Scientist with Python\n",
    "- Data Scientist Professional with Python\n",
    "- Python Programmer\n",
    "- Python Toolbox\n",
    "\n",
    "### Notes\n",
    "\n",
    "Modules for managing timezone data in Python include `zoneinfo`, `dateutil`, and `pytz`. See https://developers.home-assistant.io/blog/2021/05/07/switch-pytz-to-python-dateutil/ about problems using `pytz`. I also experienced problems using `pytz` in the \"Data Types for Data Science in Python\" course.\n",
    "\n",
    "This course uses the `dateutil` module.\n",
    "\n",
    "With the release of Python 3.9, it is recommended to use Python's `zoneinfo` module (https://docs.python.org/3/library/zoneinfo.html) and the third-party `tzdata` module (https://pypi.org/project/tzdata/), which is generally required only on Windows servers.\n",
    "\n",
    "For more information about the problems using `pytz`, see https://blog.ganssle.io/tag/timezones.html.\n",
    "\n",
    "If you're collecting data, store datetime values in UTC or with a fixed UTC offset!\n",
    "\n",
    "This is a very good course, but it should be updated to use the `zoneinfo` and `tzdata` modules.\n",
    "\n",
    "Chapter 4 (Dates and Times in pandas) of this course requires completion of the [_Data Manipulation with Pandas_](../Data%20Manipulation%20with%20Pandas/Data%20Manipulation%20with%20Pandas.ipynb) course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ea423-91af-4d04-9fb5-a214ba1624cb",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Imports are collected here for clarity and convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387cf43c-690b-4a6e-b563-ea798f5ab5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import collections\n",
    "import datetime\n",
    "import pickle\n",
    "import pprint\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import dateutil.tz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz.exceptions # for pandas support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abccd95b-8007-428e-9bd3-cc630429489a",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "| Name | File |\n",
    "| :--- | :--- |\n",
    "| Florida Hurricanes | florida_hurricane_dates.pkl |\n",
    "| W20529 Bike Data (Capital Bikeshare) | capital-onebike.csv |\n",
    "\n",
    "The bikeshare data is data for a single bicycle, W20529, for all trips in October, November, and December of 2017.\n",
    "\n",
    "### Load Florida Hurricane Data from a Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cd0d7-c03a-4556-ad73-34fdc0dadcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the .pkl file.\n",
    "# This contains a list of datetime.date objects.\n",
    "print(\"Loading Florida hurricane dates...\")\n",
    "with open(\"florida_hurricane_dates.pkl\", \"rb\") as file:\n",
    "    florida_hurricane_dates = pickle.load(file)\n",
    "print(florida_hurricane_dates[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef54dc-97a9-4939-af84-8a3fa480538e",
   "metadata": {},
   "source": [
    "### Read the Bikeshare CSV File into a pandas DataFrame\n",
    "\n",
    "The code below specifies the columns containing dates by their names. The columns can also be specified by column numbers:\n",
    "\n",
    "```Python\n",
    "onebike_df = \\\n",
    "    pd.read_csv(\n",
    "        \"capital-onebike.csv\",\n",
    "        parse_dates=[0, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2420ec7-3aa1-403f-a7a4-c5d1f519a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the CSV file to a pandas DateFrame, parsing the dates.\n",
    "# Can also use parse_dates=[0, 1].\n",
    "onebike_df = \\\n",
    "    pd.read_csv(\n",
    "        \"capital-onebike.csv\",\n",
    "        parse_dates=[\"Start date\", \"End date\"])\n",
    "print(onebike_df.info())\n",
    "print()\n",
    "print(onebike_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafbc798-c49c-41ae-bbc0-78414ffd2080",
   "metadata": {},
   "source": [
    "## Dates and Calendars\n",
    "\n",
    "### Dates in Python\n",
    "\n",
    "#### Creating Date Objects (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff601237-055f-4e12-b40a-ca6a35b3cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dates.\n",
    "# The positional arguments correspond to year, month, and day.\n",
    "two_hurricanes_dates = [datetime.date(2016, 10, 7), datetime.date(2017, 6, 21)]\n",
    "print(two_hurricanes_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c18d8-0bd1-490b-beee-4545771ef55e",
   "metadata": {},
   "source": [
    "#### Attributes of Dates (Example)\n",
    "\n",
    "Weekdays in Python begin with 0 for Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3ae44-e68c-470a-a383-0b4f9570c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"year:\", two_hurricanes_dates[0].year)\n",
    "print(\"month:\", two_hurricanes_dates[0].month)\n",
    "print(\"day:\", two_hurricanes_dates[0].day)\n",
    "print(\"weekday:\", two_hurricanes_dates[0].weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc6a9f-d076-476e-9a3a-565282d93e89",
   "metadata": {},
   "source": [
    "#### Getting the Name of the Weekday (Extra)\n",
    "\n",
    "See https://stackoverflow.com/questions/9847213/how-do-i-get-the-day-of-week-given-a-date/29519293#29519293."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabb2ed-4f49-4b31-bcb5-5dcb1a9b05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the weekday.\n",
    "weekday = two_hurricanes_dates[0].strftime(\"%A\")\n",
    "print(weekday)\n",
    "weekday2 = calendar.day_name[two_hurricanes_dates[0].weekday()]\n",
    "print(weekday2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ddcd04-8779-4e77-98b2-c86cbd5e9f10",
   "metadata": {},
   "source": [
    "#### Get the Weekday (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649aff42-2632-49cf-b7e3-1e32c3843339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On what day of the week did Hurricane Andrew occur?\n",
    "hurricane_andrew = datetime.date(1992, 8, 24)\n",
    "print(hurricane_andrew.weekday())\n",
    "# Bonus answer.\n",
    "print(hurricane_andrew.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd33f6a-813b-48dc-848c-792c7f393cfd",
   "metadata": {},
   "source": [
    "#### Count Early Florida Hurricanes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840776e-2677-413f-87fe-fd2173a1c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of early hurricanes (hurricanes arriving before June).\n",
    "early_hurricanes = 0\n",
    "for hurricane in florida_hurricane_dates:\n",
    "    if hurricane.month < 6:\n",
    "        early_hurricanes = early_hurricanes + 1\n",
    "print(early_hurricanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ed736-c8c2-4b6d-a5b3-1e1dea39ac3e",
   "metadata": {},
   "source": [
    "### Math with Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6521112-29d0-4ea8-867c-fa346980498f",
   "metadata": {},
   "source": [
    "#### Math with Dates (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ce6f3-a616-404a-834d-d3f46899b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a datetime.delta object from two datetime.date objects.\n",
    "d1 = datetime.date(2017, 11, 5)\n",
    "d2 = datetime.date(2017, 12, 4)\n",
    "l = [d1, d2]\n",
    "print(min(l))\n",
    "delta = d2 - d1\n",
    "print(type(delta))\n",
    "print(delta)\n",
    "print(delta.days)\n",
    "\n",
    "# Create a datetime.timedelta object and add it to a datetime.date.\n",
    "td = datetime.timedelta(days=29)\n",
    "print(d1 + td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e00b77-9f45-4ee3-be84-38649435a622",
   "metadata": {},
   "source": [
    "#### Subtracting Dates (Exercise)\n",
    "\n",
    "Find the number of days between the first and last hurricanes of 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65c5ac-f66c-40df-828e-1def1673ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of dates from May 9, 2007, to December 13, 2007.\n",
    "start = datetime.date(2007, 5, 9)\n",
    "end = datetime.date(2007, 12, 13)\n",
    "print((end - start).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed49976-68a0-4af0-bb4c-769f48c5003c",
   "metadata": {},
   "source": [
    "#### Counting Events per Calendar Month (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657368ad-ceec-49c6-bb2b-9ae084ed2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First approach, used by the course.\n",
    "# This has the advantage that all keys exist and they are sorted.\n",
    "hurricanes_each_month = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6:0,\n",
    "\t\t  \t\t\t\t 7: 0, 8:0, 9:0, 10:0, 11:0, 12:0}\n",
    "for hurricane in florida_hurricane_dates:\n",
    "    month = hurricane.month\n",
    "    hurricanes_each_month[month] += 1\n",
    "print(list(hurricanes_each_month.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba425eb-cdb2-4e06-83d5-bd80d7de3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second approach, using defaultdict.\n",
    "# The defaultdict is missing keys for months with no hurricanes.\n",
    "hurricanes_each_month2 = collections.defaultdict(int)\n",
    "for hurricane in florida_hurricane_dates:\n",
    "    hurricanes_each_month2[hurricane.month] += 1\n",
    "print(sorted(hurricanes_each_month2.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa0b42-1c99-4602-8608-a079e283b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third approach using Counter.\n",
    "# The Counter is missing keys for months with no hurricanes.\n",
    "hurricanes_each_month3 = collections.Counter([x.month for x in florida_hurricane_dates])\n",
    "print(sorted(hurricanes_each_month3.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a00753-b3fb-42c9-b1c0-f1ee1027ce2c",
   "metadata": {},
   "source": [
    "#### Sorting Dates (Exercise)\n",
    "\n",
    "datetime.date objects can be sorted using `sorted()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa29e3-576e-4d39-a9bc-2dd395bb3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the exercise with a subset of the data.\n",
    "dates_scrambled = [\n",
    "     datetime.date(1988, 8, 4),\n",
    "     datetime.date(1990, 10, 12),\n",
    "     datetime.date(2003, 4, 20),\n",
    "     datetime.date(1971, 9, 1),\n",
    "     datetime.date(1988, 8, 23),\n",
    "     datetime.date(1950, 8, 31),\n",
    "     datetime.date(2017, 10, 29),\n",
    "     datetime.date(2011, 7, 18),\n",
    "]\n",
    "print(dates_scrambled[0])\n",
    "print(dates_scrambled[-1])\n",
    "dates_ordered = sorted(dates_scrambled)\n",
    "print(dates_ordered[0])\n",
    "print(dates_ordered[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb4ef9-d49a-4ab1-a30d-f1a1c80bea5a",
   "metadata": {},
   "source": [
    "### Turning Dates into Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1990145-8e20-46d5-9213-9d4f4a73f437",
   "metadata": {},
   "source": [
    "#### Convert a Date to ISO 8601 Format (Example)\n",
    "\n",
    "By default, a datetime.date object is printed in ISO 8601 format, YYYY-MM-DD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3898b69-79e3-4220-8428-e43e7711c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print or convert a datetime.date object in ISO format.\n",
    "d = datetime.date(2017, 11, 5)\n",
    "print(d)\n",
    "print([d.isoformat()])\n",
    "# Sort date strings that computers once had trouble with.\n",
    "# Date strings in ISO 8601 format sort correctly.\n",
    "# This is handy for file names.\n",
    "some_dates = [\"2000-01-01\", \"1999-12-31\"]\n",
    "print(sorted(some_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d24bd7-31f0-4b1d-8933-a151d6363db6",
   "metadata": {},
   "source": [
    "#### Convert Dates to Other Formats\n",
    "\n",
    "Use the `.strftime()` method of a datetime.date object to convert a date to a string in a format that is not ISO 8601. See https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior for the documentation of `.strftime()` and `.strptime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac9316-66f6-4f0c-a546-f10b77fb8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.strftime(\"%Y\"))\n",
    "print(d.strftime(\"Year is %Y\"))\n",
    "print(d.strftime(\"%Y/%m/%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155004c5-f643-43f1-aa40-25f907db357a",
   "metadata": {},
   "source": [
    "#### Print Dates in a Friendly Format (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e53cc-74cd-41a9-af73-85f3c626aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the earliest date in ISO format and in US format.\n",
    "first_date = sorted(florida_hurricane_dates)[0]\n",
    "iso = \"Our earliest hurricane date: \" + first_date.isoformat()\n",
    "us = \"Our earliest hurricane date: \" + first_date.strftime(\"%m/%d/%Y\")\n",
    "# Extra: print the month and day without the leading 0.\n",
    "us2 = \"Our earliest hurricane date: \" +\\\n",
    "    \"{}/{}/{}\".format(first_date.month, first_date.day, first_date.year)\n",
    "print(\"ISO: \" + iso)\n",
    "print(\"US: \" + us)\n",
    "print(\"US: \" + us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467c9d7-0797-4504-a14f-c286d5d904ea",
   "metadata": {},
   "source": [
    "#### Represent Dates in Different Ways (Exercise)\n",
    "\n",
    "> Astronomers usually use the 'day number' out of 366 instead of the month and date, to avoid ambiguities between languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74de77-9aae-4dec-b951-d5c4e2e86566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the date for Hurricane Andrew in various formats.\n",
    "andrew = datetime.date(1992, 8, 26)\n",
    "# Print the date in the format 'YYYY-MM'.\n",
    "print(andrew.strftime(\"%Y-%m\"))\n",
    "# Print the date in the format 'Month (YYYY)'.\n",
    "print(andrew.strftime(\"%B (%Y)\"))\n",
    "# Print the date in the format 'YYYY-DDD'.\n",
    "print(andrew.strftime(\"%Y-%j\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d3839-13e5-4db5-87a5-72999be156ea",
   "metadata": {},
   "source": [
    "## Combining Dates and Times\n",
    "\n",
    "### Dates and Times\n",
    "\n",
    "#### Create a datetime.datetime Object (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a5305-36e6-447a-b64a-b5322c5ac781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a datetime.datetime object.\n",
    "dt = datetime.datetime(2017, 10, 1, 15, 23, 25)\n",
    "print(dt)\n",
    "print(dt.isoformat())\n",
    "# Add microseconds.\n",
    "# pandas supports billionths of seconds (nanoseconds) using the\n",
    "# pandas.TimeStamp class.\n",
    "dt = datetime.datetime(2017, 10, 1, 15, 23, 25, 500000)\n",
    "print(dt)\n",
    "# Use named arguments.\n",
    "dt = datetime.datetime(year=2017, month=10, day=1, hour=15, minute=23, second=25, microsecond=500000)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351fe5c-a85a-417f-8789-d4c8dc700f1a",
   "metadata": {},
   "source": [
    "#### Replacing Parts of a datetime.datetime Object (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76de1cf-eddd-4dbc-9877-9f4e9a015297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new datetime.datetime by replacing some attributes.\n",
    "dt_hr = dt.replace(minute=0, second=0, microsecond=0)\n",
    "print(dt_hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4bede-2baa-4e48-a402-b794c29f8ab4",
   "metadata": {},
   "source": [
    "#### Creating datetime.datetime Objects by Hand (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a5ba-533b-411b-b4fa-3a13eb4a6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print a datetime.datetime.\n",
    "dt = datetime.datetime(2017, 10, 1, 15, 26, 26)\n",
    "print(dt.isoformat())\n",
    "dt_old = dt.replace(year=1917)\n",
    "print(dt_old.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ee992-8d76-4293-a887-87ff31788c9c",
   "metadata": {},
   "source": [
    "#### Count Events before Noon Using Pandas and Numpy Methods (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d541a-b893-4b8c-8272-b883e9ec047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of start events before and after noon using the pandas\n",
    "# TimeStamp objects in the DataFrame. This is very efficient.\n",
    "start_hours = onebike_df[\"Start date\"].array.hour\n",
    "trip_counts = {\"AM\": np.sum(start_hours < 12), \"PM\": np.sum(start_hours >= 12)}\n",
    "print(trip_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043de134-838e-4551-80d8-2383bf2d4c8b",
   "metadata": {},
   "source": [
    "#### Create a List of Dictionaries from the DataFrame (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47c8e5-aa1f-47f0-8276-127b085e13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create onebike_datetimes, a list of dicts with keys \"start\" and \"end\"\n",
    "# and datetime.datetime values. It took me about an hour to figure out\n",
    "# how to do this, which was good practice with iterating through a pandas\n",
    "# DataFrame.\n",
    "\n",
    "# Extract the \"Start date\" and \"End date\" values into a list of dicts.\n",
    "# Set index=False to avoid including the index in the namedtuple.\n",
    "# In the namedtuple objects, \"Start date\" and \"End date\" were not valid\n",
    "# field names, so the fields were named \"_0\" and \"_1\".\n",
    "# In the pandas Series, the datetimes are stored as pandas TimeStamp objects,\n",
    "# which can be converted to datetime.datetime objects.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html\n",
    "onebike_datetimes = []\n",
    "for row in onebike_df.itertuples(index=False, name=\"Onebike\"):\n",
    "    start_end = {\"start\": row._0.to_pydatetime(), \"end\": row._1.to_pydatetime()}\n",
    "    onebike_datetimes.append(start_end)\n",
    "# print(onebike_datetimes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b83a3f-b2f2-4f9b-90f3-b060d547c8e7",
   "metadata": {},
   "source": [
    "#### Counting Events before Noon (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5d288-37cd-4fdf-a176-eb3ad6039e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the course's exercise, counting trips that started before noon or \n",
    "# after noon. This requires the onebike_datetimes list of dictionaries.\n",
    "trip_counts = {'AM': 0, 'PM': 0}\n",
    "for trip in onebike_datetimes:\n",
    "    if trip['start'].hour < 12:\n",
    "        trip_counts[\"AM\"] += 1\n",
    "    else:\n",
    "        trip_counts[\"PM\"] += 1\n",
    "print(trip_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b92d6-7ad7-47cc-8fb3-9dd649af913d",
   "metadata": {},
   "source": [
    "### Printing and Parsing Datetimes\n",
    "\n",
    "#### Print Datetimes (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a163d-2a44-4ad3-9c99-2b5816ad6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print datetimes.\n",
    "dt = datetime.datetime(2017, 12, 30, 15, 19, 13)\n",
    "print(dt.strftime(\"%Y-%m-%d\"))\n",
    "print(dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(dt.strftime(\"%H:%M:%S on %Y/%m/%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de145c74-98e5-4f3a-b8e6-65bb4471cee7",
   "metadata": {},
   "source": [
    "#### Parsing Datetimes from Strings (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdc81c-6d9e-45d3-9c19-4c1dccf0c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a string to create a datetime.datetime object.\n",
    "dt = datetime.datetime.strptime(\"12/30/2017 15:19:13\", \"%m/%d/%Y %H:%M:%S\")\n",
    "print(dt)\n",
    "\n",
    "# If parsing fails, a ValueError exception is raised.\n",
    "try:\n",
    "    dt = datetime.datetime.strptime(\"12/30/2017 15:19:13\", \"%m/%d/%Y\")\n",
    "except Exception as exc:\n",
    "    # These create the same output.\n",
    "    print(traceback.format_exc(limit=0))\n",
    "    # traceback.print_exception(exc, limit=0, file=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1739a2c-c269-4366-9911-14012360feeb",
   "metadata": {},
   "source": [
    "#### Convert a Unix Timestamp into a Datetime (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0016ae-c76a-404b-9f34-8fc0152b31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unix timestamps are limited to dates after January 1, 1970 UTC.\n",
    "ts = 1514665153\n",
    "dt = datetime.datetime.fromtimestamp(ts)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf4659-b264-47cb-88d8-43a083ad6982",
   "metadata": {},
   "source": [
    "#### Turning Strings into DateTimes (Exercise)\n",
    "\n",
    "> Python does not have the ability to parse non-zero-padded dates and times out of the box (such as \"1/2/2018\"). If needed, you can use other string methods to create zero-padded strings suitable for `strptime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8be91-3c29-4afa-8d8e-55636665c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to datetime.datetime objects.\n",
    "s = '2017-02-03 00:00:01'\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "d = datetime.datetime.strptime(s, fmt)\n",
    "print(d)\n",
    "\n",
    "s = '2030-10-15'\n",
    "fmt = '%Y-%m-%d'\n",
    "d = datetime.datetime.strptime(s, fmt)\n",
    "print(d)\n",
    "\n",
    "s = '12/15/1986 08:00:00'\n",
    "fmt = '%m/%d/%Y %H:%M:%S'\n",
    "d = datetime.datetime.strptime(s, fmt)\n",
    "print(d)\n",
    "\n",
    "# Non-zero-padded strings.\n",
    "s = \"1/2/2018 4:7:2\"\n",
    "fmt = \"%m/%d/%Y %H:%M:%S\"\n",
    "d = datetime.datetime.strptime(s, fmt)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dc0fe-7913-492a-ac4f-db15ddf986c6",
   "metadata": {},
   "source": [
    "#### Parsing Pairs of Strings as Datetimes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ee3fc-434f-4617-ad9a-d4d8d5a887f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with a subset of the data since I used pandas.read_csv and parsed the\n",
    "# dates already.\n",
    "onebike_datetime_strings = [\n",
    "    ('2017-10-01 15:23:25', '2017-10-01 15:26:26'),\n",
    "    ('2017-10-01 15:42:57', '2017-10-01 17:49:59'),\n",
    "    ('2017-10-02 06:37:10', '2017-10-02 06:42:53'),\n",
    "    ('2017-10-02 08:56:45', '2017-10-02 09:18:03'),\n",
    "    ('2017-10-02 18:23:48', '2017-10-02 18:45:05')\n",
    "]\n",
    "\n",
    "# Convert each pair of strings into a dictionary with keys \"start\" and \"end\".\n",
    "fmt = \"%Y-%m-%d %H:%M:%S\"\n",
    "onebike_datetimes2 = []\n",
    "for (start, end) in onebike_datetime_strings:\n",
    "    trip = {'start': datetime.datetime.strptime(start, fmt),\n",
    "            'end': datetime.datetime.strptime(end, fmt)}\n",
    "    onebike_datetimes2.append(trip)\n",
    "print(onebike_datetimes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a1225-18b7-4216-bff0-9d61ee567d67",
   "metadata": {},
   "source": [
    "#### Recreating ISO 8601 Format with `.strftime()` (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1628b3-26bc-448d-8ee4-9491afa8e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .strftime() method to format a datetime in ISO 8601 format,\n",
    "first_start = onebike_datetimes[0]['start']\n",
    "fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
    "print(first_start.isoformat())\n",
    "print(first_start.strftime(fmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0e6ab-c4ea-4462-8a09-dd15ac939c7f",
   "metadata": {},
   "source": [
    "#### Convert Unix Timestamps to Datetimes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d764569-d65b-4673-b02f-b41534a0143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Unix timestamps into datetime.datetime objects.\n",
    "timestamps = [1514665153, 1514664543]\n",
    "dts = []\n",
    "for ts in timestamps:\n",
    "    dts.append(datetime.datetime.fromtimestamp(ts))\n",
    "print(dts)\n",
    "# Output is different when printing an individual datetime.datetime object.\n",
    "for dt in dts:\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebc080-0a4f-444a-aed7-593c0fa603ca",
   "metadata": {},
   "source": [
    "### Working with Durations\n",
    "\n",
    "#### Working with Durations (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eacab1-164b-4470-b7a8-0a0c82b2d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2017, 10, 8, 23, 46, 47)\n",
    "end = datetime.datetime(2017, 10, 9, 0, 10, 57)\n",
    "duration = end - start\n",
    "print(duration.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3023313a-b944-466b-abc5-073595055e3a",
   "metadata": {},
   "source": [
    "#### Creating Timedeltas (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ff259-a1cc-4e89-97ea-04c0d0337107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and use datetime.timedelta objects.\n",
    "delta1 = datetime.timedelta(seconds=1)\n",
    "print(start)\n",
    "print(start + delta1)\n",
    "delta2 = datetime.timedelta(days=1, seconds=1)\n",
    "print(start)\n",
    "print(start + delta2)\n",
    "delta3 = datetime.timedelta(weeks=-1)\n",
    "print(start)\n",
    "print(start + delta3)\n",
    "delta4 = datetime.timedelta(weeks=1)\n",
    "print(start)\n",
    "print(start - delta4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694d968-4d78-47d9-a2e4-4ba101ba9a7c",
   "metadata": {},
   "source": [
    "#### Turning Pairs of Datetimes into Durations (Exercise)\n",
    "\n",
    "Internally, datetime.timedelta objects store days and seconds. Use the `.total_seconds()` method to get the duration in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b603767-8dc7-4b94-80ba-d76c188fc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of time the bicycle was out on each trip.\n",
    "onebike_durations = []\n",
    "for trip in onebike_datetimes:\n",
    "    trip_duration = trip[\"end\"] - trip[\"start\"]\n",
    "    trip_length_seconds = trip_duration.total_seconds()\n",
    "    onebike_durations.append(trip_length_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab8272-d1bf-47db-9e9e-79f07d397ffd",
   "metadata": {},
   "source": [
    "#### Determine Average Trip Time (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05112e-ddc2-4cc1-9935-c1e1828bc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine average trip time.\n",
    "total_elapsed_time = sum(onebike_durations)\n",
    "number_of_trips = len(onebike_durations)\n",
    "print(total_elapsed_time / number_of_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc00ba3-ba85-4c31-8672-27f258cf5092",
   "metadata": {},
   "source": [
    "#### Calculate Longest and Shortest Trips (Exercise)\n",
    "\n",
    "The shortest trip, with negative duration, happened during the conversion from daylight saving time to standard time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3b39a-f820-44cb-ad09-61debcc583c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the results look suspicious.\n",
    "shortest_trip = min(onebike_durations)\n",
    "longest_trip = max(onebike_durations)\n",
    "print(\"The shortest trip was \" + str(shortest_trip) + \" seconds\")\n",
    "print(\"The longest trip was \" + str(longest_trip) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb78af-6c62-483c-8a05-536e9bdd26a7",
   "metadata": {},
   "source": [
    "## Time Zones and Daylight Saving\n",
    "\n",
    "### UTC Offsets\n",
    "\n",
    "Clocks west of UTC are set less than UTC (UTC-xx:00); clocks east of UTC are set greater than UTC (+xx:00). UTC offsets allow us to compare times from different timezones.\n",
    "\n",
    "#### UTC (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b82e5-4c01-42c0-9f2d-cea2d6a2008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.timezone objects.\n",
    "# Eastern standard time.\n",
    "EST = datetime.timezone(datetime.timedelta(hours=-5))\n",
    "print(EST)\n",
    "# India standard time.\n",
    "IST = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
    "print(IST)\n",
    "# Create a timezone-aware datetime.datetime object.\n",
    "dt = datetime.datetime(2017, 12, 30, 15, 9, 3, tzinfo=EST)\n",
    "print(dt)\n",
    "print(dt.isoformat())\n",
    "# Convert the time to another timezone.\n",
    "print(dt.astimezone(IST))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80138e-5e98-498c-9767-d4bb2ea26e4e",
   "metadata": {},
   "source": [
    "#### Adjusting Timezone versus Changing `tzinfo` (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2001d-333d-471a-bafb-1fa2b6cab964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .replace() method to change the tzinfo of a datetime.datetime\n",
    "# object. This does not adjust the other attributes.\n",
    "# Note: Don't do this with timezones obtained from pytz!\n",
    "print(dt)\n",
    "print(dt.replace(tzinfo=datetime.timezone.utc))\n",
    "print(dt.astimezone(datetime.timezone.utc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6b129-b2e1-4412-8cf0-8f0413733683",
   "metadata": {},
   "source": [
    "#### Creating Timezone-Aware Datetimes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed210206-2540-46b3-8054-d183ae5cbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTC (Universal Coordinated Time)\n",
    "dt_utc = datetime.datetime(2017, 10, 1, 15, 26, 26, tzinfo=datetime.timezone.utc)\n",
    "print(dt_utc.isoformat())\n",
    "# PST (Pacific Standard Time)\n",
    "pst = datetime.timezone(datetime.timedelta(hours=-8))\n",
    "dt_pst = datetime.datetime(2017, 10, 1, 15, 26, 26, tzinfo=pst)\n",
    "print(dt_pst.isoformat())\n",
    "# AEDT (Australian Eastern Daylight Time)\n",
    "aedt = datetime.timezone(datetime.timedelta(hours=11))\n",
    "dt_aedt = datetime.datetime(2017, 10, 1, 15, 26, 26, tzinfo=aedt)\n",
    "print(dt_aedt.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb158e-9909-4884-9f6c-aa275bd3ced6",
   "metadata": {},
   "source": [
    "#### Setting Timezones (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace13c8e-afb7-43e0-81b1-d32a204ed7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timezone for the first 10 rows of data.\n",
    "edt = datetime.timezone(datetime.timedelta(hours=-4))\n",
    "for trip in onebike_datetimes[:10]:\n",
    "    print(\"start:\", trip[\"start\"], \"end:\", trip[\"end\"])\n",
    "    trip['start'] = trip['start'].replace(tzinfo=edt)\n",
    "    trip['end'] = trip['end'].replace(tzinfo=edt)\n",
    "    print(\"start:\", trip[\"start\"], \"end:\", trip[\"end\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccfd1b-2649-4875-bc59-97c377fb7924",
   "metadata": {},
   "source": [
    "#### What Time Did the Bike Leave in UTC? (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d7fc8-8141-4e3d-bdc5-92d6acaca5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display times for UTC.\n",
    "for trip in onebike_datetimes[:10]:\n",
    "    dt = trip['start']\n",
    "    dt = dt.astimezone(datetime.timezone.utc)\n",
    "    print('Original:', trip['start'], '| UTC:', dt.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebade84-86e9-4d50-8616-9a362c30b2ec",
   "metadata": {},
   "source": [
    "### Timezone Database\n",
    "\n",
    "Use the `dateutil` timezone database, which, because it must be updated several times a year, is not packaged with the standard Python distribution. The `dateutil.tz` database formats the names of timezones as \"Region/City\" (e.g., \"America/New_York)\").\n",
    "\n",
    "#### Timezone Database (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faab9b6-b4eb-4785-b95d-5ec4283c6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "et = dateutil.tz.gettz(\"America/New_York\")\n",
    "print(type(et))\n",
    "print(et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0c511-637e-4fc9-b08b-5eee4e0d70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = datetime.datetime(2017, 12, 30, 15, 9, 3, tzinfo=et)\n",
    "print(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56557c-b614-4415-825e-cdb23b41b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The object returned by dateutil.tz.gettz() adjusts for daylight saving time\n",
    "# automatically.\n",
    "first = datetime.datetime(2017, 10, 1, 15, 23, 25, tzinfo=et)\n",
    "print(first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ee7bd-67be-44d6-8d6e-fc9e93c245f9",
   "metadata": {},
   "source": [
    "#### Putting the Bike Trips into the Right Timezone (Exercise)\n",
    "\n",
    "We are using the Internet Assigned Numbers Authority (IANA) timezone database (https://www.iana.org/time-zones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a8833-b331-4555-862b-07a8f2e72959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over trips, updating the datetimes to be in Eastern Time\n",
    "for trip in onebike_datetimes[:10]:\n",
    "    trip['start'] = trip['start'].replace(tzinfo=et)\n",
    "    trip['end'] = trip['end'].replace(tzinfo=et)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d3354-a0bd-4992-9f5d-ee4c3e6eb728",
   "metadata": {},
   "source": [
    "#### What Time Did the Bike Leave? (Global Edition) (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5d94d-f0aa-4191-9948-ef8a778f4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timezone of a datetime.datetime object to different\n",
    "# timezones.\n",
    "# London.\n",
    "uk = dateutil.tz.gettz(\"Europe/London\")\n",
    "local = onebike_datetimes[0][\"start\"]\n",
    "notlocal = local.astimezone(uk)\n",
    "print(local.isoformat())\n",
    "print(notlocal.isoformat())\n",
    "\n",
    "# India Standard Time.\n",
    "ist = dateutil.tz.gettz(\"Asia/Kolkata\")\n",
    "notlocal = local.astimezone(ist)\n",
    "print(notlocal.isoformat())\n",
    "\n",
    "# Samoa.\n",
    "sm = dateutil.tz.gettz(\"Pacific/Apia\")\n",
    "notlocal = local.astimezone(sm)\n",
    "print(notlocal.isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a173753-8b25-4e0c-819b-51ff912619f9",
   "metadata": {},
   "source": [
    "### Starting Daylight Saving Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf459f7c-e565-4d07-a409-ca3532f85755",
   "metadata": {},
   "source": [
    "#### Start of Daylight Saving Time (Example)\n",
    "\n",
    "Watch out for how datetime.timedelta objects are calculated! See https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html. For arithmetic in the same time zone, Python uses wall time. For arithmetic in different time zones, Python uses absolute time. This behavior is documented here: https://docs.python.org/3/library/datetime.html#datetime-objects. The course is misleading about this. See also https://stackoverflow.com/questions/71428364/python-timedelta-spanning-dst-changeover-returns-incorrect-result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df628d-8cd7-414a-bac3-576f5ceacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create naitve datetime.datetime objects and compare them.\n",
    "# Do not use datetime.timedelta.totalseconds() to obtain the difference in\n",
    "# absolute time, because it calculates wall time. One way to deal with this\n",
    "# is to use the different of the .timestamp() values, which returns seconds.\n",
    "spring_ahead_159am = datetime.datetime(2017, 3, 12, 1, 59, 59)\n",
    "print(spring_ahead_159am.isoformat())\n",
    "spring_ahead_300am = datetime.datetime(2017, 3, 12, 3, 0, 0)\n",
    "print(spring_ahead_300am.isoformat())\n",
    "# It looks like using .timestamp() on a naïve datetime.datetime object\n",
    "# might apply the local timezone, and the calculation is correct.\n",
    "print(spring_ahead_300am.timestamp() - spring_ahead_159am.timestamp())\n",
    "\n",
    "# Manually add timezone information, using UTC offsets.\n",
    "EST = datetime.timezone(datetime.timedelta(hours=-5))\n",
    "EDT = datetime.timezone(datetime.timedelta(hours=-4))\n",
    "spring_ahead_159am = spring_ahead_159am.replace(tzinfo=EST)\n",
    "spring_ahead_300am = spring_ahead_300am.replace(tzinfo=EDT)\n",
    "print(spring_ahead_159am.isoformat())\n",
    "print(spring_ahead_300am.isoformat())\n",
    "# This is correct because it calculates absolute time because two\n",
    "# different timezones are used.\n",
    "print(spring_ahead_300am.timestamp() - spring_ahead_159am.timestamp())\n",
    "\n",
    "# Use dateutil.\n",
    "eastern = dateutil.tz.gettz(\"America/New_York\")\n",
    "eastern_spring_ahead_159am = datetime.datetime(2017, 3, 12, 1, 59, 59, tzinfo=eastern)\n",
    "eastern_spring_ahead_300am = datetime.datetime(2017, 3, 12, 3, 0, 0, tzinfo=eastern)\n",
    "\n",
    "# The objects appear to be identical.\n",
    "print(eastern_spring_ahead_159am.isoformat())\n",
    "print(eastern_spring_ahead_300am.isoformat())\n",
    "print(spring_ahead_159am == eastern_spring_ahead_159am)\n",
    "print(spring_ahead_300am == eastern_spring_ahead_300am)\n",
    "\n",
    "# This difference is calculated as wall time and gives a misleading result,\n",
    "# where the result is \"wall time\". Wall time is calculated when the timezone\n",
    "# info is the same for the two datetime.datetime objects.\n",
    "print((eastern_spring_ahead_300am - eastern_spring_ahead_159am).total_seconds())\n",
    "\n",
    "# Here is a way to calculate the absolute time difference:\n",
    "print(eastern_spring_ahead_300am.timestamp() - eastern_spring_ahead_159am.timestamp())\n",
    "\n",
    "# Another way is to convert to UTC before subtracting.\n",
    "utc = datetime.timezone.utc\n",
    "print((spring_ahead_300am.astimezone(utc) - spring_ahead_159am.astimezone(utc)).total_seconds())\n",
    "print((eastern_spring_ahead_300am.astimezone(utc) - eastern_spring_ahead_159am.astimezone(utc)).total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b891fe-a7aa-42d1-83f1-9e9c8e95f249",
   "metadata": {},
   "source": [
    "#### How Many Hours Elapsed Around Daylight Saving? (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003f465-b522-4077-b258-af7f3f6e7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This calculation is correct, because Python is using wall time here.\n",
    "# Start on March 12, 2017, midnight, then add 6 hours.\n",
    "start = datetime.datetime(2017, 3, 12, tzinfo = dateutil.tz.gettz('America/New_York'))\n",
    "end = start + datetime.timedelta(hours=6)\n",
    "print(start.isoformat() + \" to \" + end.isoformat())\n",
    "# How many hours have elapsed?\n",
    "print((end - start).total_seconds() / (60 * 60))\n",
    "# What if we move to UTC?\n",
    "# The timezone can be dateutil.tz.UTC or datetime.timezone.utc.\n",
    "td = end.astimezone(dateutil.tz.UTC) - start.astimezone(dateutil.tz.UTC)\n",
    "print(td.total_seconds() / (60 * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae1d90-a7b5-42c2-9504-f803a1093f73",
   "metadata": {},
   "source": [
    "#### March 29, throughout a Decade (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d94426-780f-4c69-a660-424785d779a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the UTC offset for 10 years in the past.\n",
    "# This is caused by the shift being made on a Sunday.\n",
    "dt = datetime.datetime(2000, 3, 29, tzinfo = dateutil.tz.gettz(\"Europe/London\"))\n",
    "\n",
    "# Loop over the dates, replacing the year, and print the ISO timestamp\n",
    "for y in range(2000, 2011):\n",
    "    print(dt.replace(year=y).isoformat())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515afc3a-9716-473e-978f-d433711725d3",
   "metadata": {},
   "source": [
    "### Ending Daylight Saving Time\n",
    "\n",
    "When ending daylight saving time, there are two 1:00 am times in local time. This creates an ambiguity. Here's how to check it.\n",
    "\n",
    "> Python often tries to be helpful by glossing over daylight saving time difference, and oftentimes that's what you want. However, when you do care about it, use dateutil to set the timezone information correctly and then switch into UTC for the most accurate comparisons between events.\n",
    "\n",
    "#### Ending Daylight Saving Time (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d77f8-f65a-487b-bff5-d8adf4540063",
   "metadata": {},
   "outputs": [],
   "source": [
    "eastern = dateutil.tz.gettz(\"US/Eastern\")\n",
    "first_1am = datetime.datetime(2017, 11, 5, 1, 0, 0, tzinfo=eastern)\n",
    "print(dateutil.tz.datetime_ambiguous(first_1am))\n",
    "\n",
    "# Use the enfold method to indicate the second 1:00 am moment.\n",
    "second_1am = datetime.datetime(2017, 11, 5, 1, 0, 0, tzinfo=eastern)\n",
    "second_1am = dateutil.tz.enfold(second_1am)\n",
    "print(dateutil.tz.datetime_ambiguous(second_1am))\n",
    "\n",
    "# This doesn't change the behavior during subtraction, because the\n",
    "# subtraction calculates wall time.\n",
    "print((second_1am - first_1am).total_seconds())\n",
    "\n",
    "# Convert to UTC and do the subtraction. This returns the correct result.\n",
    "first_1am = first_1am.astimezone(tz=dateutil.tz.UTC)\n",
    "second_1am = second_1am.astimezone(tz=dateutil.tz.UTC)\n",
    "print((second_1am - first_1am).total_seconds())\n",
    "\n",
    "# It's up to the code to check the fold and do the correct thing with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff7cff-25f0-4f88-a0b5-280864af5fde",
   "metadata": {},
   "source": [
    "#### Find Ambiguous Datetimes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4155b8b-24db-4ba3-a0c6-5e8c57d43d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the onebike_datetimes data and apply the \"America/New_York\" timezone.\n",
    "onebike_datetimes = []\n",
    "et = dateutil.tz.gettz(\"America/New_York\")\n",
    "for row in onebike_df.itertuples(index=False, name=\"Onebike\"):\n",
    "    start_end = {\n",
    "        \"start\": row._0.to_pydatetime().replace(tzinfo=et),\n",
    "        \"end\": row._1.to_pydatetime().replace(tzinfo=et)}\n",
    "    onebike_datetimes.append(start_end)\n",
    "# print(onebike_datetimes[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91c139-dd82-4f31-91c6-50494c40e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for ambiguous datetimes.\n",
    "# This check identifies one record that needs to be fixed.\n",
    "for trip in onebike_datetimes:\n",
    "    if dateutil.tz.datetime_ambiguous(trip[\"start\"]):\n",
    "        print(\"Ambiguous start at \" + str(trip[\"start\"]))\n",
    "        print(\"with end at \" + str(trip[\"end\"]))\n",
    "    if dateutil.tz.datetime_ambiguous(trip[\"end\"]):\n",
    "        print(\"Ambiguous end at \" + str(trip[\"end\"]))\n",
    "        print(\"with start at \" + str(trip[\"start\"]))\n",
    "        print(trip[\"end\"] - trip[\"start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf31cd2-e6e1-40fb-a674-ee3a2f533f7e",
   "metadata": {},
   "source": [
    "Avoid ambiguous datetimes in practice by storing datetimes in UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b1c834-290d-40df-8f42-f6b089231226",
   "metadata": {},
   "source": [
    "#### Clean Daylight Saving Data with Fold (Exercise)\n",
    "\n",
    "The exercise above revealed a trip with ambiguous start and end times. Since the start time was later than the end time, the start time has fold=0 and the end time has fold=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e19e5-febb-490e-9ec8-520b51fe2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shortest trip is always 116.0 seconds; a negative duration is\n",
    "# not seen.\n",
    "trip_durations = []\n",
    "for trip in onebike_datetimes:\n",
    "    # When the start is later than the end, set the fold to be 1\n",
    "    if trip[\"start\"] > trip[\"end\"]:\n",
    "        trip['end'] = dateutil.tz.enfold(trip['end'])\n",
    "    # Convert to UTC\n",
    "    start = trip['start'].astimezone(dateutil.tz.UTC)\n",
    "    end = trip['end'].astimezone(dateutil.tz.UTC)\n",
    "\n",
    "    # Subtract the difference\n",
    "    trip_length_seconds = (end - start).total_seconds()\n",
    "    trip_durations.append(trip_length_seconds)\n",
    "\n",
    "# Take the shortest trip duration\n",
    "print(\"Shortest trip: \" + str(min(trip_durations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ead422-8359-4bac-86e9-c36d952f8192",
   "metadata": {},
   "source": [
    "## Dates and Times in pandas\n",
    "\n",
    "### Reading Date and Time Data in pandas\n",
    "\n",
    "The pandas `read_csv()` method can attempt to parse dates in specific columns. If this does not work, read the data without parsing the dates and then call `pd.to_datetime()` to parse the dates using format strings.\n",
    "\n",
    "The value stored in the DataFrame is a pandas Timestamp, which is to all intents and purposes equivalent to a datetime.datetime object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4cf6fe-b331-4f4d-b5df-039893a59097",
   "metadata": {},
   "source": [
    "#### Loading Datetimes with `parse_dates` (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ffe69-15d2-42ee-b286-ec93c23e5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bikeshare data from the CSV file, parsing the dates.\n",
    "rides = pd.read_csv(\"capital-onebike.csv\", parse_dates=[\"Start date\", \"End date\"])\n",
    "print(rides.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbc9dc-a110-4b0c-a623-4a747527ce73",
   "metadata": {},
   "source": [
    "#### Converting Datetimes with `pd.to_datetime()` (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eec7b7-8ed6-40e7-bb03-5bb29de324e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bikeshare data from the CSV file, and convert the date strings\n",
    "# afterwards.\n",
    "rides2 = pd.read_csv(\"capital-onebike.csv\")\n",
    "rides2[\"Start date\"] = pd.to_datetime(rides2[\"Start date\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "rides2[\"End date\"] = pd.to_datetime(rides2[\"End date\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "print(rides2.info())\n",
    "# Show that the results are identical.\n",
    "print(rides.equals(rides2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca7548-df06-498c-944b-878f71e5b1e6",
   "metadata": {},
   "source": [
    "#### Datetime Arithmetic (Example)\n",
    "\n",
    "Now that we have datetime objects, we can computate a column named \"Duration\". (Technically, we need to fix the one row of data where the start datetime is greater than the end datetime because of the switch from daylight saving time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f323ed-167b-4fb5-9ed9-8c8cccac5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rides[\"Duration\"] = rides[\"End date\"] - rides[\"Start date\"]\n",
    "print(rides[\"Duration\"].info())\n",
    "print()\n",
    "print(type(rides[\"Duration\"][0]))\n",
    "print()\n",
    "print(rides[\"Duration\"][:5])\n",
    "print()\n",
    "print(rides[\"Duration\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12c754-b674-4360-b97a-ef7fd2ffe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the bad duration.\n",
    "print(rides[\"Duration\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92b56f-14d4-45eb-bba4-e9a461809d8b",
   "metadata": {},
   "source": [
    "pandas has convenient methods for conversion of Timedelta objects; here, we use `.dt.total_seconds()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9eab10-7f3d-4c8f-834f-14b998cb5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rides[\"Duration\"].dt.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7eef2-7117-4db7-bf37-c192858da231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for the bad row of data caused by the shift from daylight saving time\n",
    "# to standard time.\n",
    "print(rides[\"Duration\"][rides[\"Duration\"].dt.total_seconds() < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ec299-8b38-4650-8a94-9f370a0550e1",
   "metadata": {},
   "source": [
    "#### Loading a CSV file in pandas (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5247a40-67da-47f7-88bb-7f1bc388347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file, parsing the dates.\n",
    "rides3 = pd.read_csv('capital-onebike.csv', \n",
    "                    parse_dates = [\"Start date\", \"End date\"])\n",
    "print(rides3.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e98a6-5307-4670-9981-20dcdf2ce875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the \"Durations\" column.\n",
    "ride_durations = rides3[\"End date\"] - rides3[\"Start date\"]\n",
    "rides3[\"Duration\"] = ride_durations.dt.total_seconds()\n",
    "print(rides3['Duration'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690ff19-5ed1-4cb3-b510-f7205d57ee6a",
   "metadata": {},
   "source": [
    "### Summarizing Datetime Data in pandas\n",
    "\n",
    "This course is old; the instructor mentions to make sure you're using at least Pandas version 0.23.\n",
    "\n",
    "For the strings used for the first argument to `.resample()`, see https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a7630-ed41-4e46-b490-418e384e722f",
   "metadata": {},
   "source": [
    "#### Summarizing Data in pandas (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494f2b6-8dad-4da2-bf66-f2023133db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time out of dock.\n",
    "print(rides[\"Duration\"].mean())\n",
    "print(rides[\"Duration\"].median())\n",
    "print(rides[\"Duration\"].min())\n",
    "print(rides[\"Duration\"].sum())\n",
    "\n",
    "# Calculate percent of time out of the dock.\n",
    "print(rides[\"Duration\"].sum() / datetime.timedelta(days=91))\n",
    "\n",
    "# Count the number of types of riders.\n",
    "print(rides[\"Member type\"].value_counts())\n",
    "print(rides[\"Member type\"].value_counts() / len(rides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5771f-9ac4-4dcf-a94a-1f3950050bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add and use a column named \"Duration seconds\".\n",
    "rides[\"Duration seconds\"] = rides[\"Duration\"].dt.total_seconds()\n",
    "print(rides.groupby(\"Member type\")[\"Duration seconds\"].mean())\n",
    "# Ride duration per month. This looks like magic.\n",
    "print(rides.resample(\"M\", on=\"Start date\")[\"Duration seconds\"].mean())\n",
    "# Size of groups.\n",
    "print(rides.groupby(\"Member type\").size())\n",
    "# First ride for each group.\n",
    "print(rides.groupby(\"Member type\").first())\n",
    "# Quick plotting.\n",
    "rides.resample(\"M\", on=\"Start date\")[\"Duration seconds\"].mean().plot()\n",
    "plt.show()\n",
    "# Resample by days and plot.\n",
    "# The outlier was possibly a bicycle repair. Evidence supporting this is\n",
    "# that the bike was not used for several days before the outlier was\n",
    "# recorded, suggesting that the bicycle needed repair.\n",
    "rides.resample(\"D\", on=\"Start date\")[\"Duration seconds\"].mean().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ac6e6-70a8-40fa-821d-aafdcdb7062e",
   "metadata": {},
   "source": [
    "#### How Many Joyrides? (Exercise)\n",
    "\n",
    "A joyride is defined as a ride that starts and stops at the same dock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec6499-230c-4bbb-b205-d5d3bee8fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boolean series.\n",
    "joyrides = rides[\"Start station\"] == rides[\"End station\"]\n",
    "print(\"{} rides were joyrides\".format(joyrides.sum()))\n",
    "# Median of all rides.\n",
    "print(\"The median duration overall was {:.2f} seconds\"\\\n",
    "      .format(rides['Duration'].dt.total_seconds().median()))\n",
    "# Median of joyrides.\n",
    "print(\"The median duration for joyrides was {:.2f} seconds\"\\\n",
    "      .format(rides[joyrides]['Duration'].dt.total_seconds().median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516f22b-4dc2-4c6e-9f7d-1ea33a0a8dac",
   "metadata": {},
   "source": [
    "#### Plot Rides per Unit Time (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ce74-3086-4629-afaf-e1885c7d2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a trend in fewer rides per day as winter approaches?\n",
    "rides.resample(\"D\", on = 'Start date')\\\n",
    "  .size()\\\n",
    "  .plot(ylim = [0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e059f97-b604-4e15-98d8-64cd9783bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data are noisy. Try plotting the number of rides per month.\n",
    "rides.resample(\"M\", on=\"Start date\")\\\n",
    "    .size()\\\n",
    "    .plot(ylim=[0, 150])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02b012-1e96-4a33-aa32-01b3c2fe65ba",
   "metadata": {},
   "source": [
    "#### Members versus Casual Riders over Time (Exercise)\n",
    "\n",
    "> Note that by default, `.resample()` labels Monthly resampling with the last day in the month and not the first. It certainly looks like the fraction of Casual riders went down as the number of rides dropped. With a little more digging, you could figure out if keeping Member rides only would be enough to stabilize the usage numbers throughout the fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da85e0-8488-47a0-9e46-fb317eb4184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample rides to be monthly on the basis of Start date.\n",
    "monthly_rides = rides.resample(\"M\", on=\"Start date\")['Member type']\n",
    "# Take the ratio of the .value_counts() over the total number of rides\n",
    "print(monthly_rides.value_counts() / monthly_rides.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962c8e2-67ca-4f2c-b8f1-6c7adebbb347",
   "metadata": {},
   "source": [
    "#### Combining `.groupby()` and `.resample()` (Exercise)\n",
    "\n",
    "> Whereas `.resample()` groups rows by some time or date information, `.groupby()` groups rows based on the values in one or more columns.\n",
    "\n",
    "> It looks like casual riders consistently took longer rides, but that both groups took shorter rides as the months went by. Note that, by combining grouping and resampling, you can answer a lot of questions about nearly any data set that includes time as a feature. Keep in mind that you can also group by more than one column at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56579f63-3914-4aea-8e86-2a0c1f825d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rides by member type, and resample to the month.\n",
    "grouped = rides.groupby('Member type')\\\n",
    "  .resample(\"M\", on=\"Start date\")\n",
    "# Print the median duration for each group.\n",
    "print(grouped[\"Duration seconds\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0504b-9364-4e9a-8cb2-7b4cc7c2241b",
   "metadata": {},
   "source": [
    "### Additional Datetime Methods in pandas\n",
    "\n",
    "#### Timezones in pandas (Example)\n",
    "\n",
    "Finally we will deal with row 129 where the start date is in daylight time but the end date is in standard time.\n",
    "\n",
    "The datetime values we have so far are timezone-naïve; they do not have associated timezone information. In pandas use `.dt.tz_localize()` to localize a datetime to a particular timezone. This uses pytz under the hood. The plan for pandas 2.0 appears to be to switch to using the zoneinfo module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4dad7-3872-4e16-b571-80b0d4617aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rides[\"Start date\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681a277-8591-42a2-9bb7-c5a78ef85bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rides[\"Start date\"].head(3)\\\n",
    "    .dt.tz_localize(\"America/New_York\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1057d-b847-4378-8da7-3278d801e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to set a timezone for all values.\n",
    "# This raises a pytz.exceptions.AmbiguousTimeError.\n",
    "print(rides[\"Duration\"][rides[\"Duration\"].dt.total_seconds() < 0])\n",
    "try:\n",
    "    tz_rides = rides[\"Start date\"].dt.tz_localize(\"America/New_York\")\n",
    "except pytz.exceptions.AmbiguousTimeError as exc:\n",
    "    print(traceback.format_exc(limit=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3762a-9e5a-4413-8c19-6af0966617ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could have fixed the Start date value using .enfold().\n",
    "# The course sets the ambiguous times to \"NaT\", which is ignored by pandas.\n",
    "# Recalculate the \"Duration\" and \"Duration seconds\" columns.\n",
    "print(rides[\"Duration seconds\"].min())\n",
    "rides[\"Start date\"] = rides[\"Start date\"].dt.tz_localize(\"America/New_York\", ambiguous=\"NaT\").copy()\n",
    "rides[\"End date\"] = rides[\"End date\"].dt.tz_localize(\"America/New_York\", ambiguous=\"NaT\").copy()\n",
    "rides[\"Duration\"] = rides[\"End date\"] - rides[\"Start date\"]\n",
    "rides[\"Duration seconds\"] = (rides[\"End date\"] - rides[\"Start date\"]).dt.total_seconds()\n",
    "\n",
    "# Show the values for row 129.\n",
    "print(rides.iloc[129])\n",
    "\n",
    "# Now the minimum duration is positive.\n",
    "print(rides[\"Duration seconds\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9cbe02-9b6c-49b6-abd0-0d2f406f3c83",
   "metadata": {},
   "source": [
    "#### Other Datetime Operations in pandas (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980ac75-a953-474f-bd28-19ad5793d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the start year for reach row.\n",
    "print(rides[\"Start date\"].head(3).dt.year)\n",
    "# Display the day of the week for each row.\n",
    "print(rides[\"Start date\"].head(3).dt.day_name())\n",
    "# These results can be aggregated by a .groupby() call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b5d10-c638-4c17-96c9-ab6aaffa46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the indexes forward one, padding with NaT.\n",
    "print(rides[\"End date\"].shift(1).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe8eeb-9501-4417-8bcd-26ddfdb6630f",
   "metadata": {},
   "source": [
    "#### Timezones in pandas (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacd438-49ae-4de2-83f2-c857fb7ca566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This repeats work we've already accomplished.\n",
    "# Localize the Start date column to America/New_York\n",
    "# rides['Start date'] = rides['Start date'].dt.tz_localize(\"America/New_York\", ambiguous=\"NaT\")\n",
    "# Note two equivalent ways of getting to the scalar value.\n",
    "print(rides['Start date'].iloc[0])\n",
    "print(rides.iloc[0][\"Start date\"])\n",
    "# Convert the Start date column to Europe/London.\n",
    "rides['Start date'] = rides['Start date'].dt.tz_convert(\"Europe/London\")\n",
    "print(rides['Start date'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34689409-437a-4b1c-98e2-517923dc8062",
   "metadata": {},
   "source": [
    "#### How Long per Weekday? (Exercise)\n",
    "\n",
    "Calculate the median ride length for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121e40a-1dd7-4a6c-8a5e-ef7a5d4f0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the weekday of the start of the ride and\n",
    "# print the weekday and the median ride length.\n",
    "# The result don't match the course's results because the course\n",
    "# is using some different rows (e.g., row 79).\n",
    "rides['Ride start weekday'] = rides['Start date'].dt.day_name()\n",
    "print(rides.groupby(\"Ride start weekday\")['Duration seconds'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e830a30-d94e-4aa0-b473-0d5e99b33665",
   "metadata": {},
   "source": [
    "#### How Long between Rides? (Exercise)\n",
    "\n",
    "This is where shifting a column is useful. We want to compare the End date of a ride with the Start date of the next ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297a9a5-9807-415f-ab5a-83edff37fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the index of the end date up one; now subract it from the start date.\n",
    "rides['Time since'] = rides['Start date'] - (rides['End date'].shift(1))\n",
    "# Move from a timedelta to a number of seconds, which is easier to work with.\n",
    "rides['Time since'] = rides['Time since'].dt.total_seconds()\n",
    "# Resample to the month.\n",
    "monthly = rides.resample(\"M\", on=\"Start date\")\n",
    "# Print the average hours between rides each month\n",
    "print(monthly['Time since'].mean() / (60 * 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb088d15-7805-4a17-8b32-b8b3bcf4eaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
