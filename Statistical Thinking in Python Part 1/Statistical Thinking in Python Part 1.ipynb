{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Thinking in Python (Part 1)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This course is presented by Justin Bois, Lecturer at the California Institute of Technology. Collaborators are Yashas Roy and Hugo Bowne-Anderson. This is the best course I've taken so far.\n",
    "\n",
    "Prerequisite:\n",
    "- Python Data Science Toolbox (Part 2)\n",
    "\n",
    "This course is not part of any skill or career track.\n",
    "\n",
    "## Resources\n",
    "- statology.org guide to statistics using Python: https://www.statology.org/python-guides/\n",
    "- _Information Theory, Inference and Learning Algorithms_ (2003), by David McKay (I once owned this book, and now I have the free PDF)\n",
    "\n",
    "## Imports\n",
    "\n",
    "The seaborn package is imported as sns after Samuel Norman Seaborn, a character on The West Wing. I have seen other tutorials import seaborn as sb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import sklearn.datasets\n",
    "\n",
    "# Use dark mode for plotting.\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# Make the plots bigger. The default is 6.4, 4.8.\n",
    "# plt.rcParams['figure.figsize'] = [12.0, 9.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize Random Number Generator\n",
    "\n",
    "Use NumPy's new random number generators. See https://numpy.org/doc/stable/reference/random/generator.html.\n",
    "```Python\n",
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "samples = rng.normal(1, 4, size=10000)\n",
    "```\n",
    "\n",
    "In this course, we generate random numbers from the following different distributions:\n",
    "- uniform: `rng.random()`\n",
    "- binomial: `rng.binomial()`\n",
    "- normal: `rng.normal()`\n",
    "- poisson: `rng.poisson()`\n",
    "- exponential: `rng.exponential()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "\n",
    "| Data Set | File |\n",
    "| :---------- | :----- |\n",
    "| 2008 election results (all states) | 2008_all_states.csv |\n",
    "| 2008 election results (swing states) | 2008_swing_states.csv |\n",
    "| Belmont Stakes | belmont.csv |\n",
    "| Speed of light | michelson_speed_of_light.csv |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2008 Election Results (Swing States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas DataFrame.\n",
    "swing = pd.read_csv('2008_swing_states.csv')\n",
    "swing[['state', 'county', 'dem_share']].head(5)\n",
    "print(swing.info())\n",
    "print()\n",
    "print(swing.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Sepal and Petal Dimensions\n",
    "\n",
    "The data set is available from scikit-learn.org: https://scikit-learn.org/https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html. See https://scikit-learn.org/stable/datasets/index.html#iris-plants-dataset for a description of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris Data from scikit-learn into a pandas DataFrame.\n",
    "# This requires some customization.\n",
    "bunch = sklearn.datasets.load_iris(as_frame=True)\n",
    "iris = bunch[\"frame\"] # this is the DataFrame\n",
    "species_names = bunch[\"target_names\"] # names of targets\n",
    "# Add a species column and drop the target column.\n",
    "iris[\"species\"] = [species_names[x] for x in iris[\"target\"]]\n",
    "iris = iris.drop(columns=[\"target\"])\n",
    "print(iris.info())\n",
    "print()\n",
    "print(iris.head())\n",
    "print()\n",
    "\n",
    "# Extract the data for Iris versicolor as a NumPy array.\n",
    "# This is not needed, since plt.hist() accepts a pandas Series.\n",
    "versicolor_petal_length = iris[iris[\"species\"] == \"versicolor\"][\"petal length (cm)\"].to_numpy()\n",
    "print(versicolor_petal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2008 Election Results (All States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2008 election results for all states into a pandas DataFrame.\n",
    "# Read the data from the CSV file.\n",
    "all_states = pd.read_csv(\"2008_all_states.csv\")\n",
    "print(all_states.info())\n",
    "print()\n",
    "print(all_states.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Michelson Speed of Light Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Michelson Speed of Light Data into a pandas DataFrame.\n",
    "# Plot a histogram.\n",
    "light = pd.read_csv(\"michelson_speed_of_light.csv\", index_col=0)\n",
    "print(light.info())\n",
    "print()\n",
    "print(light.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graphical Exploratory Data Analysis\n",
    "\n",
    "### Introduction to Exploratory Data Analysis\n",
    "\n",
    "- EDA is the process of organizing, plotting, and summarizing a data set.\n",
    "- Tukey's book _Exploratory Data Analysis_ (1977) was very influential.\n",
    "- Example: 2008 US swing state election results at the county level from Pennsylvania, Ohio, and Florida (data obtained from http://www.data.gov/).\n",
    "\n",
    "The video displays a histogram of the number of counties for the y axis and percent of vote for Obama (in 10% intervals) for the x axis. (This is done in an exercise below.)\n",
    "\n",
    "\n",
    "The histogram shows that more counties in these three states voted for McCain than for Obama. (But what about the total number of votes for each candidate?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tukey's Comments on EDA (Exercise)\n",
    "\n",
    "In his book, Tukey wrote:\n",
    "- Exploratory data analysis is detective work.\n",
    "- There is no excuse for failing to plot and look at data.\n",
    "- The greatest value of a picture is that it forces us to notice what we never expected to see.\n",
    "- It is important to understand what you _can do_ before you learn how to measure _how well_ you seem to have done it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Graphical EDA (Exercise)\n",
    "- It often involves converting tabular data into graphical form.\n",
    "- If done well, graphical representations can allow for more rapid interpretation of data.\n",
    "- There is no excuse for neglecting to do graphical EDA.\n",
    "- But a nice looking plot is not always the end goal of statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a Histogram\n",
    "- For this course and its sequel, we can use numpy arrays and pandas DataFrames interchangeably.\n",
    "- This code uses `_` as a dummy variable to capture output to prevent it from being displayed by the Python IDE.\n",
    "- _Always_ label your axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a Histogram, Letting MatplotLib Define the Bins (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Matplotlib define the bins, where the default number is 10.\n",
    "# The bin boundaries here are not what we want.\n",
    "_ = plt.hist(swing['dem_share'])\n",
    "_ = plt.xlabel('Percent of vote for Obama')\n",
    "_ = plt.ylabel('Number of counties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Bin Edges of the Histogram (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges for plotting.\n",
    "bin_edges = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "_ = plt.hist(swing['dem_share'], bins=bin_edges)\n",
    "_ = plt.xlabel('Percent of vote for Obama')\n",
    "_ = plt.ylabel('Number of counties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the Histogram Bin Number to 20 (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of bins to 20. This moves the bars so they are not\n",
    "# aligned well.\n",
    "_ = plt.hist(swing['dem_share'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `np.linspace` to Set the Histogram Bin Edges (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.linspace to calculate the bin edges and the xticks values.\n",
    "# This is the best way.\n",
    "_ = plt.hist(swing[\"dem_share\"], bins=np.linspace(0, 100, 21))\n",
    "_ = plt.xlabel('Percent of vote for Obama')\n",
    "_ = plt.ylabel('Number of counties')\n",
    "_ = plt.xticks(np.linspace(0, 100, 11, dtype=int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justin Bois prefers the default settings of Seaborn, a matplotlib-based statistical data visualization package written primarily by Michael Waskom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use seaborn to Make a Nicer Histogram (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Seaborn to make a nicer plot.\n",
    "# sns.set() changes the global defaults for all plots using the matplotlib\n",
    "# rcParams system.\n",
    "# Reset the figure size again.\n",
    "sns.set()\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.rcParams['figure.figsize'] = [12.0, 9.0]\n",
    "\n",
    "# Plot the figure again using the Seaborn settings.\n",
    "# I made some improvements with bin edges and x axis ticks.\n",
    "_ = plt.hist(swing[\"dem_share\"], bins=np.linspace(0, 100, 21))\n",
    "_ = plt.xlabel('Percent of vote for Obama')\n",
    "_ = plt.ylabel('Number of counties')\n",
    "_ = plt.xticks(np.linspace(0, 100, 11, dtype=int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting a Histogram of Iris Data (Exercise)\n",
    "\n",
    "I added the axes labels in the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Histogram for _Iris versicolor_ Petal Length (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram from the pandas Series for Iris versicolor petal length.\n",
    "# Set the bin boundaries every 0.2 cm, giving 11 bins.\n",
    "# Include axis labels.\n",
    "bins = np.linspace(2.8, 5.4, 14)\n",
    "xticks = np.linspace(2.8, 5.4, 14)\n",
    "_ = plt.hist(iris[iris[\"species\"] == \"versicolor\"][\"petal length (cm)\"], bins=bins)\n",
    "_ = plt.xticks(xticks)\n",
    "_ = plt.xlabel('Petal length (cm)')\n",
    "_ = plt.ylabel('Number of petals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the Number of Bins in a Histogram (Exercise)\n",
    "\n",
    "The \"square root rule\" is a commonly-used rule of thumb for choosing the number of bins, where the number of bins is the square root of the number of samples. Use `np.sqrt` to calculate the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 50 samples, so we want about 7 bins.\n",
    "# My concern here is that we have a resolution of 0.1 cm for the measurements.\n",
    "# So we could set boundary intervals at 0.3 cm. This gives 7 bins containing\n",
    "# samples.\n",
    "bins = np.linspace(2.7, 5.4, 10)\n",
    "_ = plt.hist(versicolor_petal_length, bins=bins)\n",
    "_ = plt.xlabel('Petal length (cm)')\n",
    "_ = plt.ylabel('Count')\n",
    "_ = plt.xticks(bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting All of Your Data: Bee Swarm Plots\n",
    "- A major drawback of using histograms is the number of bins chosen changes the look of the data set; the number of bins is often arbitrary; and this leads to binning bias.\n",
    "- The same data may be interpreted differently depending on choice of bins.\n",
    "- Another problem with histograms is that we are not plotting all of the data. We are sweeping the data into bins and losing their actual values. (For example, when there are 11 values in a bin, we don't know the actual values.)\n",
    "- One way to remedy this is to make a seaborn bee swarm plot. A requirement is that the data be in a well-organized DataFrame. This is the example code from the video:\n",
    "\n",
    "```Python\n",
    "_ = sns.swarmplot(x=\"state\", y=\"dem_share\", data=swing)\n",
    "_ = plt.xlabel(\"State\")\n",
    "_ = plt.ylabel(\"Percent of vote for Obama\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Bee Swarm Plot from the Election Data (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bee swarm plot from the election data.\n",
    "_ = sns.swarmplot(x=\"state\", y=\"dem_share\", data=swing)\n",
    "_ = plt.xlabel(\"State\")\n",
    "_ = plt.ylabel(\"Percent of vote for Obama\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Iris Data as a Bee Swarm Plot (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bee swarm plot of the iris petal lengths.\n",
    "_ = sns.swarmplot(x='species', y='petal length (cm)', data=iris)\n",
    "_ = plt.xlabel('Species')\n",
    "_ = plt.ylabel('Petal length (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting a Bee Swarm Plot (Exercise)\n",
    "\n",
    "_I. virginica_ petals tend to be the longest, and _I. setosa_ petals tend to be the shortest of the three species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting All of Your Data: Empirical Cumulative Distribution Functions\n",
    "Creating beeswarm plots of the voting data, separating counties into two categories, west and east of the Mississippi River, creates blobs of data that are difficult to interpret. The plot points overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Bee Swarm Plot (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bee swarm plot of all counties in the United States, separating\n",
    "# \"east\" and \"west\" in the \"east_west\" column.\n",
    "# Note that seaborn creates axis labels (even if they're not very good).\n",
    "# Because there is so much data, the plot is difficult to interpret.\n",
    "_ = sns.swarmplot(x=\"east_west\", y=\"dem_share\", data=all_states)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Empirical Cumulative Distriction Function Plot (Demonstration)\n",
    "\n",
    "An Empirical Cumulative Distribution Function (ECDF) plot can reveal other information.\n",
    "\n",
    "Justin almost always plots an ECDF first before performing any other EDA.\n",
    "\n",
    "Make an ECDF from voting data from the counties of the three swing states, FL, OH, and PA. Examination of the ECDF reveals that 20% of the counties had less than 36% of the votes for Obama. 75% of counties had less than 50% of the votes for Obama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create the ECDF.\n",
    "# Sort the data by the \"dem_share\" column.\n",
    "x = np.sort(swing[\"dem_share\"])\n",
    "# Set the values of y from 1/len(x) to 1.\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "# Create a line plot without drawing the lines.\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "_ = plt.xlabel('Percent of vote for Obama in county')\n",
    "_ = plt.ylabel('ECDF')\n",
    "# Keep the data off the plot edges.\n",
    "plt.margins(0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the ECDFs for Swing State Data (Demonstration)\n",
    "\n",
    "Plot the ECDFs for the three swing states, FL, OH, and PA. What is necessary is to select rows of database based on the value in the state column. This page shows how to do this: https://cmdlinetips.com/2018/02/how-to-subset-pandas-dataframe-based-on-values-of-a-column/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECDF for Florida.\n",
    "is_fl = swing['state'] == 'FL'\n",
    "df_fl = swing[is_fl]\n",
    "x_fl = np.sort(df_fl['dem_share'])\n",
    "y_fl = np.arange(1, len(x_fl) + 1) / len(x_fl)\n",
    "_ = plt.plot(x_fl, y_fl, marker='.', linestyle='none')\n",
    "\n",
    "# ECDF for Ohio.\n",
    "is_oh = swing['state'] == 'OH'\n",
    "df_oh = swing[is_oh]\n",
    "x_oh = np.sort(df_oh['dem_share'])\n",
    "y_oh = np.arange(1, len(x_oh) + 1) / len(x_oh)\n",
    "_ = plt.plot(x_oh, y_oh, marker='.', linestyle='none')\n",
    "\n",
    "# ECDF for Pennsylvania.\n",
    "is_pa = swing['state'] == 'PA'\n",
    "df_pa = swing[is_pa]\n",
    "x_pa = np.sort(df_pa['dem_share'])\n",
    "y_pa = np.arange(1, len(x_pa) + 1) / len(x_pa)\n",
    "_ = plt.plot(x_pa, y_pa, marker='.', linestyle='none')\n",
    "\n",
    "# Axis labels.\n",
    "_ = plt.xlabel('Percent of vote for Obama in county')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "# Keep the data off the plot edges.\n",
    "plt.margins(0.02)\n",
    "\n",
    "# Add a legend; by default this is in the upper left.\n",
    "# Add loc='lower right' to move the legend.\n",
    "plt.legend(['FL', 'OH', 'PA'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the ECDF (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that takes as input a 1-D array of data and returns the\n",
    "# x and y values of the ECDF.\n",
    "def ecdf(data):\n",
    "    \"\"\"\n",
    "    Compute the ECDF of a one-dimensional array of measurements.\n",
    "\n",
    "    x, y = ecdf(data)\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the ECDF (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ECDF for the petal lengths of Anderson's Iris versicolor\n",
    "# flowers and plot the ECDF.\n",
    "versicolor_petal_length = iris[iris[\"species\"] == \"versicolor\"][\"petal length (cm)\"]\n",
    "x_vers, y_vers = ecdf(versicolor_petal_length)\n",
    "_ = plt.plot(x_vers, y_vers, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of ECDFs (Exercise)\n",
    "\n",
    "Plot the ECDFs of the petal lengths of all three _Iris_ species. This is the incomplete code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDFs of the petal lengths of all three iris species.\n",
    "setosa_petal_length = iris[iris[\"species\"] == \"setosa\"][\"petal length (cm)\"]\n",
    "versicolor_petal_length = iris[iris[\"species\"] == \"versicolor\"][\"petal length (cm)\"]\n",
    "virginica_petal_length = iris[iris[\"species\"] == \"virginica\"][\"petal length (cm)\"]\n",
    "\n",
    "x_set, y_set = ecdf(setosa_petal_length)\n",
    "x_vers, y_vers = ecdf(versicolor_petal_length)\n",
    "x_virg, y_virg = ecdf(virginica_petal_length)\n",
    "\n",
    "# Plot all ECDFs on the same plot\n",
    "plt.plot(x_set, y_set, marker='.', linestyle='none')\n",
    "plt.plot(x_vers, y_vers, marker='.', linestyle='none')\n",
    "plt.plot(x_virg, y_virg, marker='.', linestyle='none')\n",
    "\n",
    "# Annotate the plot\n",
    "plt.legend(('setosa', 'versicolor', 'virginica'), loc='lower right')\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The ECDFs expose clear differences among the species.\" _I. setosa_ has much shorter petals and also \"less absolute variability in petal length\" than _I. versicolor_ and _I. virginica_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onward Toward the Whole Story\n",
    "- We have three graphing tools in our toolbox:\n",
    "    - histogram\n",
    "    - swarm plot\n",
    "    - empirical cumulative distribution function\n",
    "- And we can make comparative plots in the same figure.\n",
    "- For nearly every data set we will encounter, we start with graphical exploratory data analysis.\n",
    "- \"Exploratory data analysis can never be the whole story, but nothing else can serve as the foundation stone.\" â€” John Tukey\n",
    "- Coming up:\n",
    "    - next chapter: quantitative EDA -- summary statistics\n",
    "    - second half of the course:\n",
    "        - thinking probabilistically\n",
    "        - discrete and continuous distributions\n",
    "    - the power of hacker statistics using objects from numpy.random to simulate data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sample Mean and Median\n",
    "\n",
    "Use `np.mean()` and `np.median()` to calculate the mean and median of a data vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Petal Length (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean petal length for Iris versicolor.\n",
    "print(\"I. versicolor mean petal length:\", np.mean(versicolor_petal_length), \"cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles, Outlier, and Box Plots\n",
    "\n",
    "#### Calculate Percentiles of the Swing State Data (Demonstration)\n",
    "\n",
    "Use `np.percentile()` to calculate any percentile of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles of the swing data.\n",
    "print(np.percentile(swing[\"dem_share\"], [25, 50, 75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Box Plot of the Election Data (Demonstration)\n",
    "\n",
    "The box of a box plot extends from the 25th to the 75th percentile (the interquartile range, or IQR). The horizontal line is placed at the 50th percentile (the median). The whiskers extend above and below 1.5 times the interquartile range. If the data comes from a normal distribution, the box and whiskers include 99% of the data. Outliers beyond the whiskers, beyond two IQR from the median, are plotted individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using what we learned in the \"Introduction to Data Visualization with \n",
    "# Matplolib\", create a box plot of the election data.\n",
    "fig, ax = plt.subplots()\n",
    "# Subset the data for convenience.\n",
    "east = all_states[all_states[\"east_west\"] == \"east\"]\n",
    "west = all_states[all_states[\"east_west\"] == \"west\"]\n",
    "# Plot the subsets.\n",
    "ax.boxplot([west[\"dem_share\"], east[\"dem_share\"]], labels=[\"West\", \"East\"])\n",
    "ax.set_xlabel(\"East or west of the Mississippi\")\n",
    "ax.set_ylabel(\"Democratic share of the vote\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Box Plot Using seaborn (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a box plot using seaborn. This is just like using seaborn to create a\n",
    "# bee swarm plot.\n",
    "sns.set(rc={\"figure.figsize\": (6, 6)})\n",
    "plt.style.use(\"dark_background\")\n",
    "_ = sns.boxplot(x=\"east_west\", y=\"dem_share\", data=all_states)\n",
    "_ = plt.xlabel(\"Region\")\n",
    "_ = plt.ylabel(\"Percent of vote for Obama\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Box Plots by State for All Voting Data (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots by state.\n",
    "# See https://www.statology.org/matplotlib-boxplot-by-group/ for creating\n",
    "# a boxplot by groups; seaborn makes this very easy.\n",
    "# Subset and sort the data by state.\n",
    "dem_share = all_states[[\"state\", \"dem_share\"]].sort_values(\"state\", axis=0)\n",
    "# Make the figure extra wide to prevent overlap of state abbreviations.\n",
    "sns.set(rc={\"figure.figsize\": (18, 8)})\n",
    "plt.style.use(\"dark_background\")\n",
    "sns.boxplot(x=\"state\", y=\"dem_share\", data=dem_share)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Percentiles (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 2.5th, 25th, 50th, 75th, and 97.5th percentiles of\n",
    "# I. versicolor petal lengths.\n",
    "percentiles = np.array([2.5, 25, 50, 75, 97.5])\n",
    "v_ptiles = np.percentile(versicolor_petal_length, percentiles)\n",
    "print(v_ptiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Percentiles on ECDF Plot (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the ECDF figure, plot the positions of the percentiles calculated above.\n",
    "# The x value is v_ptiles, the y value is percentiles / 100.\n",
    "sns.set(rc={\"figure.figsize\": (6, 4)})\n",
    "plt.style.use(\"dark_background\")\n",
    "x_vers, y_vers = ecdf(versicolor_petal_length)\n",
    "_ = plt.plot(x_vers, y_vers, marker='.', linestyle='none')\n",
    "_ = plt.plot(v_ptiles, percentiles / 100, marker=\"D\", color=\"red\", linestyle=\"none\")\n",
    "_ = plt.xlabel('petal length (cm)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Box Plots of _Iris_ Petal Lengths (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots of the iris petal length data.\n",
    "sns.set(rc={\"figure.figsize\": (4, 4)})\n",
    "plt.style.use(\"dark_background\")\n",
    "sns.boxplot(x=\"species\", y=\"petal length (cm)\", data=iris)\n",
    "plt.xlabel(\"species\")\n",
    "plt.ylabel(\"petal length (cm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and Standard Deviation\n",
    "\n",
    "Variance is the mean squared distance of the data from their mean. It is a measure of the spread of the data. The standard deviation is the square root of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance and standard deviation of the voter data for Florida.\n",
    "dem_share_FL = swing[swing[\"state\"] == \"FL\"][\"dem_share\"]\n",
    "var_FL = np.var(dem_share_FL)\n",
    "print(\"variance FL:\", var_FL)\n",
    "sqrt_var_FL = np.sqrt(var_FL)\n",
    "print(\"sqrt(var_FL):\", sqrt_var_FL)\n",
    "std_FL = np.std(dem_share_FL)\n",
    "print(\"standard deviation FL:\", std_FL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Variance (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the variance directly and by using np.var().\n",
    "differences = versicolor_petal_length - np.mean(versicolor_petal_length)\n",
    "diff_sq = differences ** 2\n",
    "variance_explicit = np.mean(diff_sq)\n",
    "variance_np = np.var(versicolor_petal_length)\n",
    "print(variance_explicit, variance_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Standard Deviation (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sqrt(var()) and std().\n",
    "print(np.sqrt(np.var(versicolor_petal_length)) == np.std(versicolor_petal_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and the Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Scatter Plot of Swing State Data (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of vote share for Obama (y axis) vs. total votes\n",
    "# (x axis). There appears to be a correlation.\n",
    "sns.set(rc={\"figure.figsize\": (6.4, 4.8)})\n",
    "plt.style.use(\"dark_background\")\n",
    "_ = plt.scatter(swing[\"total_votes\"] / 1000, swing[\"dem_share\"])\n",
    "_ = plt.xlabel(\"Total votes (thousands)\")\n",
    "_ = plt.ylabel(\"Democratic share of votes (percent)\")\n",
    "_ = plt.yticks(np.arange(0, 101, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way to plot the data is to call \n",
    "# plt.plot(x, y, marker=\"o\", linestyle=\"none\")\n",
    "_ = plt.plot(swing[\"total_votes\"] / 1000, swing[\"dem_share\"],\n",
    "            marker=\"o\", linestyle=\"none\")\n",
    "_ = plt.xlabel(\"Total votes (thousands)\")\n",
    "_ = plt.yticks(np.arange(0, 101, 10))\n",
    "_ = plt.ylabel(\"Democratic share of votes (percent)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Correlation Coefficient for the Swing State Data (Demonstration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance is:\n",
    "\n",
    "    sum((x(i) - mean(x)) * (y(i) - mean(y))) / n\n",
    "\n",
    "The Pearson correlation coefficient is a dimensionless number that is:\n",
    "\n",
    "    cov(x, y) / (std(x) * std(y))\n",
    "\n",
    "The correlation coefficient is the variability due to codependence divided by the independent variabilies. The correlation coefficient (rho) varies from -1 through 0 to 1. A value of 0 indicates no correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson's correlation coefficient for the swing DataFrame.\n",
    "# The covariance matrix calculates the cov(x, x), cov(x, y), cov(y, x) and\n",
    "# cov(y, y).\n",
    "rho1 = np.corrcoef(swing[[\"total_votes\", \"dem_share\"]], rowvar=False)[0, 1]\n",
    "print(\"rho1:\", rho1)\n",
    "# An alternate way to pass the data to np.corrcoef().\n",
    "rho2 = np.corrcoef(swing[\"total_votes\"], swing[\"dem_share\"])[0, 1]\n",
    "print(\"rho2:\", rho2)\n",
    "# Make the calculation using np.cov().\n",
    "num3 = np.cov(swing[[\"total_votes\", \"dem_share\"]], rowvar=False)[0, 1]\n",
    "denom3 = np.sqrt(np.cov(swing[\"total_votes\"])) * np.sqrt(np.cov(swing[\"dem_share\"]))\n",
    "rho3 = num3 / denom3\n",
    "print(\"rho3:\", rho3)\n",
    "# Make the calculation using np.var().\n",
    "num4 = np.cov(swing[[\"total_votes\", \"dem_share\"]], rowvar=False)[0, 1]\n",
    "denom4 = np.sqrt(np.var(swing[\"total_votes\"])) * np.sqrt(np.var(swing[\"dem_share\"]))\n",
    "rho4 = num4 / denom4\n",
    "print(\"rho4:\", rho4)\n",
    "# Make the calculation using np.std().\n",
    "num5 = np.cov(swing[[\"total_votes\", \"dem_share\"]], rowvar=False)[0, 1]\n",
    "denom5 = np.std(swing[\"total_votes\"]) * np.std(swing[\"dem_share\"])\n",
    "rho5 = num5 / denom5\n",
    "print(\"rho5:\", rho5)\n",
    "print()\n",
    "\n",
    "# The calculations for standard deviation do not give quite the same results.\n",
    "# What causes this?\n",
    "print(\"sqrt(cov(x)):\", np.sqrt(np.cov(swing[\"total_votes\"])))\n",
    "print(\"sqrt(var(x)):\", np.sqrt(np.var(swing[\"total_votes\"])))\n",
    "print(\"std(x):\", np.std(swing[\"total_votes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Scatter Plot of Petal Width versus Petal Length (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of petal width vs. petal length for I. versicolor.\n",
    "versicolor_petal_width = iris[iris[\"species\"] == \"versicolor\"][\"petal width (cm)\"]\n",
    "_ = plt.plot(versicolor_petal_length, versicolor_petal_width, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel(\"Petal length (cm)\")\n",
    "_ = plt.ylabel(\"Petal width (cm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Covariance Matrix of Petal Length and Petal Width (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = np.cov(versicolor_petal_length, versicolor_petal_width)\n",
    "print(\"covariance_matrix:\", covariance_matrix)\n",
    "petal_cov = covariance_matrix[0, 1]\n",
    "print(petal_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Pearson Correlation Coefficient (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for calculating and returning the Pearson\n",
    "# correlation coefficient.\n",
    "def pearson_r(x, y):\n",
    "    corr_mat = np.corrcoef(x, y)\n",
    "    return corr_mat[0, 1]\n",
    "\n",
    "r = pearson_r(versicolor_petal_length, versicolor_petal_width)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using np.var() or np.std() in the calculation gives an erroneous result.\n",
    "print(petal_cov / (np.std(versicolor_petal_length) * np.std(versicolor_petal_width)))\n",
    "print(petal_cov / (np.sqrt(np.var(versicolor_petal_length)) * np.sqrt(np.var(versicolor_petal_width))))\n",
    "print(petal_cov / (np.sqrt(np.cov(versicolor_petal_length)) * np.sqrt(np.cov(versicolor_petal_width))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking Probabilistically -- Discrete Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Logic and Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What Is the Goal of Statistical Inference? (Exercise)\n",
    "\n",
    "What is the goal of statistical inference? All of these are true:\n",
    "- To draw probabilistic conclusions about what we might expect if we collected the same data again.\n",
    "- To draw actionable conclusions from the data.\n",
    "- To draw more general conclusions from relatively few data or observations.\n",
    "\n",
    "#### Why Do We Use the Language of Probability? (Exercise)\n",
    "Why do we use the language of probability?\n",
    "- Probability provides a measure of uncertainty.\n",
    "- Data are almost never exactly the same when acquired again, and probability allows us to say how much we expect them to vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Number Generators and Hacker Statistics\n",
    "\n",
    "Hacker statistics uses simulated repeated measurements to compute probabilities. A Bernoulli trial has two outcomes (here, heads or tails) with probabilities p and 1 - p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate Coin Flips (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wrote this before watching most of the video.\n",
    "# I improved the code (function flip_four) after watching the video.\n",
    "# Simulate coin flips to estimate the probability of four heads in four\n",
    "# coin flips (p=1/16 (0.0625)).\n",
    "def flip_four():\n",
    "    \"\"\"\n",
    "    Flip a coin four times and return the number of heads.\n",
    "    \"\"\"\n",
    "    random_numbers = rng.random(4)\n",
    "    heads = random_numbers < 0.5\n",
    "    return np.sum(heads)\n",
    "\n",
    "def simulate_coin_flips(repeats):\n",
    "    run_count = 0\n",
    "    four_heads_count = 0\n",
    "    for i in range(repeats):\n",
    "        heads_count = flip_four()\n",
    "        if heads_count == 4:\n",
    "            four_heads_count += 1\n",
    "        run_count += 1\n",
    "    proportion = four_heads_count / run_count\n",
    "    return proportion\n",
    "\n",
    "runs = 1000 # runs of coin flip repeats\n",
    "repeats = 1000 # 4 coin flips per repeat\n",
    "probs = np.empty(runs)\n",
    "for k in range(runs):\n",
    "    probs[k] = simulate_coin_flips(repeats)\n",
    "\n",
    "# Plot the ECDF of the results.\n",
    "# The ticks are optimized for looking for four heads.\n",
    "x, y = ecdf(probs)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel('Observed proportion')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()\n",
    "\n",
    "# Plot a histogram.\n",
    "bins = 10\n",
    "plt.hist(probs, bins=bins)\n",
    "_ = plt.xlabel('Observed proportion')\n",
    "_ = plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a Histogram of Samples Taken from the Uniform Distribution (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at values taken from the uniform distribution.\n",
    "# This uses an empty NumPy ndarray.\n",
    "random_numbers = np.empty(100000)\n",
    "for i in range(100000):\n",
    "    random_numbers[i] = rng.random()\n",
    "# Plot a histogram of the results.\n",
    "_ = plt.hist(random_numbers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the ECDFof Samples Taken from the Uniform Distribution (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDF of the results.\n",
    "x, y = ecdf(random_numbers)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel('Random number')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a Function for Performing Bernoulli Trials (Exercise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function for performing Bernoulli trials.\n",
    "def perform_bernoulli_trials(n, p):\n",
    "    \"\"\"\n",
    "    Perform n Bernoulli trials with success probability p\n",
    "    and return number of successes.\n",
    "    \"\"\"\n",
    "    n_success = 0\n",
    "    for i in range(n):\n",
    "        random_number = rng.random()\n",
    "        if random_number < p:\n",
    "            n_success += 1\n",
    "    return n_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Mortgage Loan Defaults (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the probability of a default on a loan is 0.05 (one in twenty),\n",
    "# simulate the distribution for the number of defaults in 100 loans,\n",
    "# running the simulation 1000 times.\n",
    "# Use the density argument instead of the normed argument. The course is using\n",
    "# matplotlib 3.1.2, where the normed parameter was still allowed but was\n",
    "# was deprecated in favor of the density parameter.\n",
    "# I am using matplotlib 3.5.2.\n",
    "n_defaults = np.empty(1000)\n",
    "for i in range(1000):\n",
    "    n_defaults[i] = perform_bernoulli_trials(100, 0.05)\n",
    "_ = plt.hist(n_defaults, density=True, bins=np.arange(0, 16))\n",
    "_ = plt.xlabel('Number of defaults out of 100 loans')\n",
    "_ = plt.ylabel('Observed probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Mortgage Loan Defaults ECDF (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDF.\n",
    "x, y = ecdf(n_defaults)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel(\"Number of defaults\")\n",
    "_ = plt.ylabel(\"ECDF\")\n",
    "plt.show()\n",
    "\n",
    "# The bank will lose money if 10 or more loans go into default.\n",
    "# What is the observed probability that the bank will lose money?\n",
    "prob = np.sum(n_defaults >= 10) / len(n_defaults)\n",
    "print(\"Estimated probability of losing money on 100 loans:\", prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distributions and Stories: The Binomial Distribution\n",
    "\n",
    "The probability mass function (PMF) is the set of probabilities of discrete outcomes. For example, consider rolling a die, where the discrete outcomes (events) are 1, 2, 3, 4, 5, or 6, and the probability of each outcome is 1/6. The PMF associated with rolling a 6-sized die is a discrete uniform PMF.\n",
    "\n",
    "The PMF is a property of a discrete probability distribution, where a probability distribution is a description of the possible mathematical outcomes.\n",
    "\n",
    "The outcome of rolling a single die is (1) discrete, and (2) uniformly distributed.\n",
    "\n",
    "The story associated with the coin flipping example is: The number r of successes in n Bernoulli trials with probability p of success is binomially distributed. The number of heads in four coin flips matches this story, since a coin flip is a Bernoulli trial with p = 0.5.\n",
    "\n",
    "We can call np.binomial using two arguments: the number of Bernoulli trials, and the probability of success. We can specify size to obtain the results of more than one Bernoulli trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Small Random Sample from the Binomial Distribution (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.binomial(4, 0.5, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Large Random Sample from the Binomial Distribution and Plot It (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large sample from the binomial distribution.\n",
    "n = 60\n",
    "p = 0.1\n",
    "results = rng.binomial(n, p, size=100000)\n",
    "\n",
    "# The values being plotted are discrete values that are integers here.\n",
    "# Arrange each bin to go from, e.g., 0.0 to 1.0, etc.\n",
    "bins = np.arange(0, np.max(results) + 2)\n",
    "_ = plt.hist(results, bins=bins, density=True)\n",
    "_ = plt.xlabel(\"Successes\")\n",
    "_ = plt.ylabel(\"Probability\")\n",
    "_ = plt.xticks(np.arange(0, np.max(results) + 2, 2))\n",
    "plt.show()\n",
    "\n",
    "# Arrange each bin to go from, e.g., -0.5 to 0.5, etc.\n",
    "bins = np.arange(0, np.max(results) + 2) - 0.5\n",
    "_ = plt.hist(results, bins=bins, density=True)\n",
    "_ = plt.xlabel(\"Successes\")\n",
    "_ = plt.ylabel(\"Probability\")\n",
    "_ = plt.xticks(np.arange(0, np.max(results) + 2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the ECDF of the Random Sample from the Binomial Distribution (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDF of the result.\n",
    "x, y = ecdf(results)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.ylabel(\"ECDF\")\n",
    "_ = plt.xlabel(\"Number of successes\")\n",
    "_ = plt.xticks(np.arange(0, np.max(results) + 2, 2))\n",
    "_ = plt.title(\"n = 60, p = 0.1\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the ECDF of the Binomial Distribution (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning to the bank loan problem, we can generate samples much more\n",
    "# efficiently using np.random.binomial. Increase the number of rsamples\n",
    "# for each run from 1000 to 10000.\n",
    "# The CDF we're plotting is the binomial distribution.\n",
    "n_defaults = rng.binomial(n=100, p=0.05, size=10000)\n",
    "x, y = ecdf(n_defaults)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.xlabel(\"Number of defaults\")\n",
    "_ = plt.ylabel(\"ECDF\")\n",
    "_ = plt.title(\"p = 0.05, n = 100\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the PMF of the Binomial Distribution (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the binomial probability mass fundtion (PMF) using a histogram.\n",
    "# Again, shift the coordinates on the x axis (as above).\n",
    "# The course says add 2 to np.max(n_defaults) before subtracting 0.5.\n",
    "# If the biggest value is 14, we need a bin from 13.5 to 14.5.\n",
    "# To get there, we need np.arange(0, 16) - 0.5. Yes, we need to add 2. \n",
    "plt.hist(n_defaults, bins=np.arange(0, np.max(n_defaults) + 2) - 0.5, density=True)\n",
    "plt.xlabel(\"Number of defaults\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Processes and the Poisson Distribution\n",
    "\n",
    "In a Poisson process, the timing of the next event is completely independent of when the previous event happened. \n",
    "Every event is independent. What Justin didn't mention: The probability of a success is the same for every event.\n",
    "\n",
    "David McKay, in his book _Information Theory, Inference and Learning Algorithms_, imagines a town called Poissonville in which bus arrival is a Poisson process. The arrival of the next bus is completely independent of the previous bus.\n",
    "\n",
    "The following are Poisson processes:\n",
    "- natural births at a given hospital\n",
    "- website hits during a given hour\n",
    "- meteor strikes\n",
    "- molecular collisions in a gas\n",
    "- aviation incidents\n",
    "- buses in Poissonville\n",
    "\n",
    "The Poisson distribution has one parameter, lambda. The number r of arrivals of a Poisson process in a given time interval with an average rate of lambda arrivals per interval is Poisson distributed.\n",
    "\n",
    "For example, the number of web hits per hour when the average rate is 6 hits per hour is Poisson distributed.\n",
    "\n",
    "The Poisson distribution is the limit of the binomial distribution for a low probability of success and a large number of trials. That is, events are rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain and Plot a Large Random Sample from the Poisson Distribution (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a sample of 10,000 events from the Poisson distribution.\n",
    "samples = rng.poisson(6, size=10000)\n",
    "x, y = ecdf(samples)\n",
    "_ = plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "_ = plt.margins(0.02)\n",
    "_ = plt.xlabel(\"Number of successes\")\n",
    "_ = plt.ylabel(\"ECDF\")\n",
    "_ = plt.title(\"lambda = 6\")\n",
    "_ = plt.xticks(np.arange(0, np.max(samples) + 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship Between Binomial and Poisson Distributions (Exercise)\n",
    "\n",
    "A quote from the lesson:\n",
    "> You just heard that the Poisson distribution is a limit of the Binomial distribution for rare events. This makes sense if you think about the stories. Say we do a Bernoulli trial every minute for an hour, each with a success probability of 0.1. We would do 60 trials, and the number of successes is Binomially distributed, and we would expect to get about 6 successes. This is just like the Poisson story we discussed in the video, where we get on average 6 hits on a website per hour. So, the Poisson distribution with arrival rate equal to _np_ approximates a Binomial distribution for _n_ Bernoulli trials with probability _p_ of success (with _n_ large and _p_ small). Importantly, the Poisson distribution is often simpler to work with because it has only one parameter instead of two for the Binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the Binomial Distribution to the Poisson Distribution (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the binomial distribution to the Poisson distribution.\n",
    "# Draw 10,000 samples out of Poisson distribution: samples_poisson\n",
    "samples_poisson = rng.poisson(10, size=10000)\n",
    "print('Poisson:     ', np.mean(samples_poisson),\n",
    "                       np.std(samples_poisson))\n",
    "\n",
    "# Specify values of n and p to consider for Binomial: n, p\n",
    "# np = 10.\n",
    "n = [20, 100, 1000, 10000, 50000]\n",
    "p = [0.5, 0.1, 0.01, 0.001, 0.0002]\n",
    "\n",
    "# Draw 10,000 samples for each n,p pair: samples_binomial\n",
    "for i in range(len(n)):\n",
    "    samples_binomial = rng.binomial(n=n[i], p=p[i], size=10000)\n",
    "    print('n =', n[i], 'Binom:', np.mean(samples_binomial),\n",
    "                                 np.std(samples_binomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: The means are all about the same, but the standard deviation of the binomial distribution approaches that of the Poisson distribution as n gets larger and p gets smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Many No-Hitters in a Season? (Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the exercise:\n",
    "\n",
    "> In baseball, a no-hitter is a game in which a pitcher does not allow the other team to get a hit. This is a rare event, and since the beginning of the so-called modern era of baseball (starting in 1901), there have only been 251 of them through the 2015 season in over 200,000 games. The ECDF of the number of no-hitters in a season is shown to the right. Which probability distribution would be appropriate to describe the number of no-hitters we would expect in a given season?\n",
    "\n",
    "> Note: The no-hitter data set was scraped and calculated from the data sets available at retrosheet.org (license)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 2015, there were 7 no-hitters, where the average per season is 215/115.\n",
    "# If we model this using the Poisson distribution, what is the probability\n",
    "# of observing 7 no-hitters in a season?\n",
    "# The p-value is ~0.007. Perhaps this means a Poisson distribution is not a \n",
    "# good way to model the data because the events are not independent or the\n",
    "# probability is not the same over 115 years.\n",
    "sample_size=100000\n",
    "n_nohitters = rng.poisson(251 / 115, size=sample_size)\n",
    "n_large = np.sum(n_nohitters >= 7)\n",
    "p_large = n_large / sample_size\n",
    "print('Probability of seven or more no-hitters:', p_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking Probabilistically -- Continuous Variables\n",
    "\n",
    "### Probability Density Functions\n",
    "\n",
    "Albert Michelson's measurements of the speed of light in megameters per second are modeled well by the normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: Analyze the Michelson Speed of Light Data (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ECDF plot.\n",
    "x, y = ecdf(light[\"velocity of light in air (km/s)\"])\n",
    "plt.plot(x, y, linestyle=\"none\", marker=\".\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.xlabel(\"Speed of light (km/sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a histogram.\n",
    "# I later set bins=9 to match the histogram in the slide.\n",
    "plt.hist(light[\"velocity of light in air (km/s)\"], bins=9, density=True)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Speed of light (km/sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seaborn bee swarm plot.\n",
    "_ = sns.swarmplot(x=None, y=\"velocity of light in air (km/s)\", data=light)\n",
    "_ = plt.ylabel(\"Speed of light (km/sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seaborn box plot.\n",
    "_ = sns.boxplot(x=None, y=\"velocity of light in air (km/s)\", data=light)\n",
    "_ = plt.ylabel(\"Speed of light (km/sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Probability Density Function (PDF) is the continuous analog of the Probability Mass Function used for discrete data. It provides a mathematical description of the relative likelihood of observing a value of a continuous variable. Areas under the PDF curve give probabilities. To calculate the probabilities, we need the Cumulative Distribution Function. The CDF gives the probability that the speed of light is less than the value on the x axis. The value at 300,000 km/sec estimates that the probability that the speed of light is less than 300,000 km/sec is 97%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the Normal Distribution\n",
    "\n",
    "The normal distribution describes a continuous variable whose PDF has a single symmetrical peak. (There is more to the normal distribution than that, but the course doesn't cover that.) The normal distribution has two parameters, mu (the mean), the middle of the peak; and sigma (the standard deviation), a measure of the width of the data. These parameters should not be confused with the mean and standard deviation computed from data; these are estimates of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Michelson Data as a Histogram and Overlay the PDF of the Normal Distribution (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a histogram and overlay the PDF of the normal distribution.\n",
    "# To do this, we need scipy.stats.norm.pdf to calculate the y value given\n",
    "# the x value.\n",
    "# See https://www.geeksforgeeks.org/how-to-plot-a-normal-distribution-with-matplotlib-in-python/.\n",
    "# Calculate estimates of mu and sigma (mu and standard deviation).\n",
    "\n",
    "# Plot the histogram.\n",
    "plt.hist(light[\"velocity of light in air (km/s)\"], bins=9, density=True)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.xlabel(\"Speed of light (km/sec)\")\n",
    "\n",
    "# Calculate estimates of the mean and standard deviation from the data.\n",
    "mean = np.mean(light[\"velocity of light in air (km/s)\"])\n",
    "stddev = np.std(light[\"velocity of light in air (km/s)\"])\n",
    "\n",
    "# Create points (x_n, y_n) for plotting.\n",
    "x_n = np.arange(299500, 300201)\n",
    "y_n = scipy.stats.norm.pdf(x_n, mean, stddev)\n",
    "\n",
    "# Plot the curve of the PDF.\n",
    "plt.plot(x_n, y_n, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the normality of the Michelson data by comparing its ECDF against the ECDF of samples taken from the normal distribution using the estimated mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the ECDF Curves for the Michelson Data (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the ECDF curves presented in the video.\n",
    "# Using the mean and standard deviation calculated above, collect a random\n",
    "# sample of 10,000 points from the normal distribution.\n",
    "samples_nn = rng.normal(mean, stddev, size=10000)\n",
    "x_nn, y_nn = ecdf(samples_nn)\n",
    "plt.plot(x_nn, y_nn, linestyle=\"none\", marker=\".\", color=\"red\")\n",
    "\n",
    "# Plot the observed data over the top.\n",
    "x, y = ecdf(light[\"velocity of light in air (km/s)\"])\n",
    "plt.plot(x, y, linestyle=\"none\", marker=\".\")\n",
    "\n",
    "# Add labels and show the plot.\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.xlabel(\"Speed of light (km/sec)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justin concluded that the Michelson data are approximately normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the PDFs and ECDFs of Three Normal Distributions (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hacker statistics to simulate the probability density functions of\n",
    "# three normal curves with the same mean but different standard deviations.\n",
    "# Create the data points.\n",
    "samples_std1 = rng.normal(20, 1, size=100000)\n",
    "samples_std3 = rng.normal(20, 3, size=100000)\n",
    "samples_std10 = rng.normal(20, 10, size=100000)\n",
    "# Create the histograms.\n",
    "plt.hist(samples_std1, bins=100, density=True, histtype=\"step\")\n",
    "plt.hist(samples_std3, bins=100, density=True, histtype=\"step\")\n",
    "plt.hist(samples_std10, bins=100, density=True, histtype=\"step\")\n",
    "# Add a legend and show the plot.\n",
    "_ = plt.legend(('std = 1', 'std = 3', 'std = 10'))\n",
    "plt.ylim(-0.01, 0.42)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same sample points, plot the ECDFs of the three distributions.\n",
    "x_std1, y_std1 = ecdf(samples_std1)\n",
    "x_std3, y_std3 = ecdf(samples_std3)\n",
    "x_std10, y_std10 = ecdf(samples_std10)\n",
    "# Create the plots.\n",
    "marker = \".\"\n",
    "markersize = 1\n",
    "linestyle = \"none\"\n",
    "plt.plot(x_std1, y_std1, marker=marker, markersize=markersize, linestyle=linestyle)\n",
    "plt.plot(x_std3, y_std3, marker=marker, markersize=markersize, linestyle=linestyle)\n",
    "plt.plot(x_std10, y_std10, marker=marker, markersize=markersize, linestyle=linestyle)\n",
    "# Label and show the plot.\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.xlabel(\"x\")\n",
    "_ = plt.legend(('std = 1', 'std = 3', 'std = 10'), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution: Properties and Warnings\n",
    "\n",
    "The normal distribution is used to model much naturally occurring data, but it isn't always appropriate (for example, the mass of large-mouth bass in Massachusetts). With the normal distribution, it is extremely unlikely to find points beyond 4 standard deviations from the mean. Observations with many outliers are not well described by the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the Results of the Belmont Stakes Normally Distributed? (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the results of the Belmont Stakes normally distributed?\n",
    "# The file contains duration data in min:sec. I would need to figure out\n",
    "# how to convert these. (One way is to use regular expressions, but there\n",
    "# is probably a way in NumPy or pandas to do the same thing.\n",
    "# Copy the data from the course.\n",
    "belmont_no_outliers = np.array([\n",
    "       148.51, 146.65, 148.52, 150.7 , 150.42, 150.88, 151.57, 147.54,\n",
    "       149.65, 148.74, 147.86, 148.75, 147.5 , 148.26, 149.71, 146.56,\n",
    "       151.19, 147.88, 149.16, 148.82, 148.96, 152.02, 146.82, 149.97,\n",
    "       146.13, 148.1 , 147.2 , 146.  , 146.4 , 148.2 , 149.8 , 147.  ,\n",
    "       147.2 , 147.8 , 148.2 , 149.  , 149.8 , 148.6 , 146.8 , 149.6 ,\n",
    "       149.  , 148.2 , 149.2 , 148.  , 150.4 , 148.8 , 147.2 , 148.8 ,\n",
    "       149.6 , 148.4 , 148.4 , 150.2 , 148.8 , 149.2 , 149.2 , 148.4 ,\n",
    "       150.2 , 146.6 , 149.8 , 149.  , 150.8 , 148.6 , 150.2 , 149.  ,\n",
    "       148.6 , 150.2 , 148.2 , 149.4 , 150.8 , 150.2 , 152.2 , 148.2 ,\n",
    "       149.2 , 151.  , 149.6 , 149.6 , 149.4 , 148.6 , 150.  , 150.6 ,\n",
    "       149.2 , 152.6 , 152.8 , 149.6 , 151.6 , 152.8 , 153.2 , 152.4 ,\n",
    "       152.2 ])\n",
    "# Calculate estimates of the mean and standard deviation.\n",
    "mu_est = np.mean(belmont_no_outliers)\n",
    "sigma_est = np.std(belmont_no_outliers)\n",
    "# Create samples from a normal distribution.\n",
    "samples = rng.normal(mu_est, sigma_est, size=10000)\n",
    "# Get the ECDFs of the observed and random data.\n",
    "x_obs, y_obs = ecdf(belmont_no_outliers)\n",
    "x_sam, y_sam = ecdf(samples)\n",
    "# Plot the ECDFs.\n",
    "plt.plot(x_sam, y_sam, marker=\".\", linestyle=\"none\")\n",
    "plt.plot(x_obs, y_obs, marker=\".\", linestyle=\"none\")\n",
    "plt.xlabel(\"Belmont winning time (sec)\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.legend((\"Theoretical\", \"Observed\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The course concludes:\n",
    "> The theoretical CDF and the ECDF of the data suggest that the winning Belmont times are, indeed, Normally distributed. This also suggests that in the last 100 years or so, there have not been major technological or training advances that have significantly affected the speed at which horses can run this race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the Probability of a Horse beating Secretariat's Record (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hacker statistics to estimate the probability of a horse beating\n",
    "# Secretariat's record. Use 1 million samples.\n",
    "sample_size = 1000000\n",
    "samples2 = rng.normal(mu_est, sigma_est, size=sample_size)\n",
    "secretariat = 144\n",
    "prob = np.sum(samples2 < secretariat) / sample_size\n",
    "print(\"prob =\", prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Exponential Distribution\n",
    "\n",
    "Returning to Poissonville, where buses arriving per hour are Poisson distributed, the waiting times for buses are exponentially distributed. That is, the waiting time between arrivals of a Poisson process is exponentially distributed. The single parameter of the exponential distribution is the mean waiting time. The distribution does not have a peak, as shown by its PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Theoretical PDF of the Exponential Distribution (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PDF of the exponential distribution with a mean waiting time of 1.\n",
    "# Use the function in scipy.stats.\n",
    "exp_mean = 0\n",
    "x_e = np.linspace(0, 10, 100)\n",
    "# scale is 1/theta, where theta is the mean.\n",
    "y_e = scipy.stats.expon.pdf(x_e, scale=1)\n",
    "plt.plot(x_e, y_e)\n",
    "plt.xticks(range(0, 11, 2))\n",
    "plt.yticks(np.arange(0, 11, 2) / 10)\n",
    "plt.xlabel(\"Time units\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the PDF of the Exponential Distribution Using Hacker Statistics (Demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PDF using hacker statistics.\n",
    "samples_exp = rng.exponential(1.0, size=10000)\n",
    "plt.hist(samples_exp, bins=100, density=True, histtype=\"step\")\n",
    "# bins = np.linspace(0, 10, 101)\n",
    "# plt.hist(samples_exp, bins=bins, density=True, histtype=\"step\")\n",
    "plt.xticks(range(0, 11, 2))\n",
    "plt.yticks(np.arange(0, 11, 2) / 10)\n",
    "plt.xlabel(\"Time units\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the 5 largest values.\n",
    "np.sort(samples_exp)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclear incidents can be modeled well as a Poisson process. The times between incidents are modeled by the exponential distribution. I don't have access to the data. Justin creates the CDF from the data and from samples taken from the exponential distribution (`rng.exponential()`).\n",
    "\n",
    "\"If you can simulate a story, you can get its distribution [through using a computer].\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Between Major League No-Hitters (Exercise)\n",
    "\n",
    "Time between Major League no-hitters can be modeled using the exponential distribution. This is explored in the \"Statistical Thinking in Python (Part 2)\" course.\n",
    "\n",
    "#### What Distribution Should Be Used to Model Waiting for the Next Secretariat? (Exercise)\n",
    "\n",
    "Waiting for the next Secretariat:\n",
    "> Exponential: A horse as fast as Secretariat is a rare event, which can be modeled as a Poisson process, and the waiting time between arrivals of a Poisson process is Exponentially distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Waiting Time for Two Consecutive Poisson Processes (Exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of, \"If you have a story, you can simulate it.\"\n",
    "# Waiting time between no-hitters can be modeled using the exponential\n",
    "# distribution with its scale value (the mean waiting time).\n",
    "# Similarly, the waiting time between hitting the cycle can be modeled\n",
    "# using the exponential distribution with its own scale value.\n",
    "# How long must we wait to see a no-hitter followed by hitting the cycle?\n",
    "# Write a function to add these together.\n",
    "def successive_poisson(tau1, tau2, size=1):\n",
    "    \"\"\"\n",
    "    Compute time for arrival of two successive Poisson processes.\n",
    "    \"\"\"\n",
    "    # Draw samples out of first exponential distribution.\n",
    "    t1 = np.random.exponential(tau1, size)\n",
    "    # Draw samples out of second exponential distribution.\n",
    "    t2 = np.random.exponential(tau2, size)\n",
    "    # Return the sum of the times.\n",
    "    return t1 + t2\n",
    "\n",
    "# Put the successive_poisson function to use.\n",
    "# The mean waiting time for a no-hitter is 764 games.\n",
    "# The mean waiting time for hitting the cycle is 715 games.\n",
    "# Draw samples of waiting times: waiting_times\n",
    "waiting_times = successive_poisson(764, 715, 100000)\n",
    "_ = plt.hist(waiting_times, bins=100, density=True, histtype=\"step\")\n",
    "_ = plt.xlabel(\"Games\")\n",
    "_ = plt.ylabel(\"PDF\")\n",
    "plt.show()\n",
    "mean_waiting_time = np.mean(waiting_times)\n",
    "print(\"Mean waiting time:\", int(mean_waiting_time), \"games\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Notice that the PDF is peaked, unlike the waiting time for a single Poisson process.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ECDF.\n",
    "x, y = ecdf(waiting_times)\n",
    "plt.plot(x, y, marker=\".\", linestyle=\"none\")\n",
    "plt.xlabel(\"Games\")\n",
    "plt.ylabel(\"ECDF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "Justin provides a quick outline of what will be presented in _Statistical Thinking in Python (Part 2)_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
